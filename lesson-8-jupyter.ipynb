{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part II: Deep Learning from the Foundations\n",
    "\n",
    "> *NOTE: The document is mostly made from notes that I typed while in the class, that's why it is messy sometimes. It is a work in progress. When watching the videos I will be continuously updating the notes.*\n",
    "\n",
    "## Intro\n",
    "- Very different part II of previous year\n",
    "- We will implement fastai library from foundations (from scratch)\n",
    "    - Basic matrix calculus\n",
    "    - Training loops\n",
    "    - Optimizers customized\n",
    "    - Customized annealing\n",
    "    - Actually something where you can train world class models\n",
    "- Read and implement papers\n",
    "- Solve applications that are not fully backed in the fastai library\n",
    "- In the end, implement on Swift\n",
    "- So many papers nowaday\n",
    "    - and says minor variations of the same thing\n",
    "- Show the foundations so that you can choose your 12 papers\n",
    "- Cutting edge is really about engineer, not about papers\n",
    "    - Who can bake that things in code\n",
    "- Part II will be more about bottom up (with code)\n",
    "- Create your own algorithm to solve the things you do.\n",
    "- Today we'll implement matrix multiplication from scratch with Python\n",
    "\n",
    "## Embracing Swift for Deep Learning\n",
    "- Chris\n",
    "    - Built compilers, C for Mac\n",
    "    - Built the most recent language\n",
    "    - Currently dedicating his life to deep learning\n",
    "- Julia has pottential as well!\n",
    "- S4TF Pros\n",
    "    - Write everything in swift\n",
    "    - See whats happening\n",
    "    - opportunities\n",
    "- Cons\n",
    "    - Minimal Ecosystem\n",
    "    - Very little works\n",
    "    - Lots to learn\n",
    "- PyTorch Pros\n",
    "    - Get work done now\n",
    "    - Great ecosystem\n",
    "    - Docs and tutorials\n",
    "- Cons\n",
    "    - Performance\n",
    "    - Pythons types\n",
    "    - Mismatch with backend libs\n",
    "- Swift will possibibly take place in this field\n",
    "\n",
    "## What do we mean by from the foudations?\n",
    "Recreate fastai and much of pytorch? matrix multiply, torch.nn, using:\n",
    "- Python\n",
    "- Python stdlib\n",
    "- Non ds modules\n",
    "- Pytorch array creation, RGN, indexer\n",
    "- fastai.datasets\n",
    "- matplotlib\n",
    "\n",
    "## But why?\n",
    "- Really experiment\n",
    "- Understand it by creating it\n",
    "- Correlate papers with code\n",
    "- Tweak everythin\n",
    "- Contribute\n",
    "\n",
    "## There are many opportunities in this class\n",
    "- Your homework will be at the cutting edge\n",
    "- Few DL practictioners know what you know now\n",
    "- Experiment lots, especially in your area of expertise\n",
    "- Much of what you find will have not be written about before\n",
    "- Don't wait to be perfect before you start communicating\n",
    "    - > Write stuff down for the You of 6 months ago, that's your audience\n",
    "- If you don't have a blog, try medium.com\n",
    "\n",
    "## Recap of part I\n",
    "- He assumes that you don't remember everything.\n",
    "- As we go on, if necessary, you go back and watch that video\n",
    "- Especially the second half\n",
    "- He assumes that you know know about SGD from the scratch\n",
    "- Topics\n",
    "    - Convolutions\n",
    "    - Weight decay\n",
    "    - Dropout\n",
    "    - ...\n",
    "\n",
    "## Overfit > Reduce overfitting > There's no step 3\n",
    "- Try to make sure we can train good models\n",
    "- There are ~~three~~two steps for trainig a good model\n",
    "1. First we try to create something with way more capacity than we need\n",
    "    - No regularization\n",
    "    - Overfit\n",
    "2. Overfitting does not mean training loss lower than validation loss\n",
    "    - A wealthy model almost always will have such behavior\n",
    "    - **Overfitting is when you actually see your validation loss getting worse**\n",
    "- Possible three would be visualize output\n",
    "- One is easy, the two is more difficult.\n",
    "\n",
    "## Five steps to avoid overfitting\n",
    "1. More data\n",
    "2. Data augmentation\n",
    "3. Generalizable architectures\n",
    "4. Regularization\n",
    "5. Reduce archtecture complexity\n",
    "\n",
    "- Most begginers start with 5 but that should be the last\n",
    "    - Unless the model is too slow\n",
    "\n",
    "## It's time to start reading papers\n",
    "- Even familiar stuff look complex in a paper!\n",
    "- Papers are important for deep learning beyond the basics, but hard to read\n",
    "- Google for a blog post describing the paper\n",
    "    - They are not selected for their outstanding clarity of comunication\n",
    "    - Usually a blog post will do the job way better than the paper does\n",
    "- Learn to produce greek letters\n",
    "\n",
    "\n",
    "## List of mathematical symbols on Wikipedia\n",
    "- https://en.wikipedia.org/wiki/List_of_mathematical_symbols\n",
    "- or use [detexify](http://detexify.kirelabs.org/classify.html)\n",
    "\n",
    "# In the next couple of lessons\n",
    "\n",
    "## Steps to a basic modern CNN model\n",
    "> We are going to create a pretty confident modern CNN model\n",
    "\n",
    "- Matmul\n",
    "- Relu/init\n",
    "- Fully Connected foward\n",
    "- Fully Connected backward\n",
    "- Train loop\n",
    "- Conv\n",
    "- Optim\n",
    "- Batch-norm\n",
    "- Resnet\n",
    "    - We already have this last one from Part 1\n",
    "\n",
    "**Goal of today's class**\n",
    "- Go from matrix multiplication to backward pass\n",
    "\n",
    "## [Lesson 00.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/00_exports.ipynb)\n",
    "- How to buld an app on jupyter notebooks\n",
    "- More productive on Jupyter notebooks\n",
    "\n",
    "### How to pull out bits of code from jupyter into a package\n",
    "- Use the special comment `#export` to tell the system a cell that you want to keep and reuse.  \n",
    "- Then use the file [`notebook2script.py`](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/notebook2script.py) which goes through the program and find cells with the special comment `#export` and put them into a python module.\n",
    "    - Path.stem.split(\"-\") is used for the output filename, hence, the output name is the first portion before an undesrcore. If there's no underscore, then the full name.\n",
    "    - The exported module goes to a folder called `exp`\n",
    "- We can then import the exported module using `from exp.nb_00 import *`\n",
    "- Creating a test framework\n",
    "    - `test` and `test_eq` using `assert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TEST = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fire\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/b7/205702f348aab198baecd1d8344a90748cb68f53bdcd1cc30cbc08e47d3e/fire-0.1.3.tar.gz\n",
      "Requirement already satisfied: six in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fire) (1.12.0)\n",
      "Building wheels for collected packages: fire\n",
      "  Running setup.py bdist_wheel for fire ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/wittmann/Library/Caches/pip/wheels/2a/1a/4d/6b30377c3051e76559d1185c1dbbfff15aed31f87acdd14c22\n",
      "Successfully built fire\n",
      "Installing collected packages: fire\n",
      "Successfully installed fire-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1078  100  1078    0     0   2661      0 --:--:-- --:--:-- --:--:--  2661\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fastai/fastai_docs/master/dev_course/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "import json,fire,re\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "def is_export(cell):\r\n",
      "    if cell['cell_type'] != 'code': return False\r\n",
      "    src = cell['source']\r\n",
      "    if len(src) == 0 or len(src[0]) < 7: return False\r\n",
      "    #import pdb; pdb.set_trace()\r\n",
      "    return re.match(r'^\\s*#\\s*export\\s*$', src[0], re.IGNORECASE) is not None\r\n",
      "\r\n",
      "def notebook2script(fname):\r\n",
      "    fname = Path(fname)\r\n",
      "    fname_out = f'nb_{fname.stem.split(\"_\")[0]}.py'\r\n",
      "    main_dic = json.load(open(fname,'r'))\r\n",
      "    code_cells = [c for c in main_dic['cells'] if is_export(c)]\r\n",
      "    module = f'''\r\n",
      "#################################################\r\n",
      "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\r\n",
      "#################################################\r\n",
      "# file to edit: dev_nb/{fname.name}\r\n",
      "\r\n",
      "'''\r\n",
      "    for cell in code_cells: module += ''.join(cell['source'][1:]) + '\\n\\n'\r\n",
      "    # remove trailing spaces\r\n",
      "    module = re.sub(r' +$', '', module, flags=re.MULTILINE)\r\n",
      "    open(fname.parent/'exp'/fname_out,'w').write(module[:-2])\r\n",
      "    print(f\"Converted {fname} to {fname_out}\")\r\n",
      "\r\n",
      "if __name__ == '__main__': fire.Fire(notebook2script)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted lesson-8-jupyter.ipynb to nb_lesson-8-jupyter.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d=json.load(open('lesson-8-jupyter.ipynb', 'r'))['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': None,\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': ['#export\\n', \"TEST = 'test'\"]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv exp/nb_lesson-8-jupyter.py exp/nb_00.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_00 import *\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f'{cname}:\\n{a}\\n{b}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp=operator.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eq'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\ntest\nTest",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-df5801f4ca3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-50-57ae53f6feb1>\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-8c73df044e01>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{cname}:\\n{a}\\n{b}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\ntest\nTest"
     ]
    }
   ],
   "source": [
    "test_eq(TEST, 'Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use [`run_notebook.py`](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/run_notebook.py) to run the tests outside of the jupyter notebook\n",
    "    - `python run_notebook.py 01_matmul.ipynb` run the tests outside of the jupyter notebook\n",
    "    - We can see the assertion error when running in the terminal\n",
    "- Now we have an automatable unit test framework on jupyter notebook\n",
    "- Fire to execute a function\n",
    "    - **It takes any function and automatically converts into a command-line interface**\n",
    "    - Inputs of a function are converted into arguments in the command-line\n",
    "- Notebooks are json files.\n",
    "    - We can import cells and play around jupyter notebook files converting them to json files\n",
    "    - Example: `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   319  100   319    0     0   1476      0 --:--:-- --:--:-- --:--:--  1476\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fastai/fastai_docs/master/dev_course/dl2/run_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md               lesson-8.md             run_notebook.py\r\n",
      "\u001b[34mexp\u001b[m\u001b[m/                    notebook2script.py\r\n",
      "lesson-8-jupyter.ipynb  \u001b[34mpapers\u001b[m\u001b[m/\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "import nbformat,fire\r\n",
      "from nbconvert.preprocessors import ExecutePreprocessor\r\n",
      "\r\n",
      "def run_notebook(path):\r\n",
      "    nb = nbformat.read(open(path), as_version=nbformat.NO_CONVERT)\r\n",
      "    ExecutePreprocessor(timeout=600).preprocess(nb, {})\r\n",
      "    print('done')\r\n",
      "\r\n",
      "if __name__ == '__main__': fire.Fire(run_notebook)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat run_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"run_notebook.py\", line 11, in <module>\r\n",
      "    if __name__ == '__main__': fire.Fire(run_notebook)\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/fire/core.py\", line 127, in Fire\r\n",
      "    component_trace = _Fire(component, args, context, name)\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/fire/core.py\", line 366, in _Fire\r\n",
      "    component, remaining_args)\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/fire/core.py\", line 542, in _CallCallable\r\n",
      "    result = fn(*varargs, **kwargs)\r\n",
      "  File \"run_notebook.py\", line 8, in run_notebook\r\n",
      "    ExecutePreprocessor(timeout=600).preprocess(nb, {})\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/nbconvert/preprocessors/execute.py\", line 361, in preprocess\r\n",
      "    nb, resources = super(ExecutePreprocessor, self).preprocess(nb, resources)\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/nbconvert/preprocessors/base.py\", line 69, in preprocess\r\n",
      "    nb.cells[index], resources = self.preprocess_cell(cell, resources, index)\r\n",
      "  File \"/Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages/nbconvert/preprocessors/execute.py\", line 385, in preprocess_cell\r\n",
      "    raise CellExecutionError.from_cell_and_msg(cell, out)\r\n",
      "nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:\r\n",
      "------------------\r\n",
      "test_eq(TEST, 'Test')\r\n",
      "------------------\r\n",
      "\r\n",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\r\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)\r\n",
      "\u001b[0;32m<ipython-input-18-df5801f4ca3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\r\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEST\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32m<ipython-input-13-57ae53f6feb1>\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\r\n",
      "\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\r\n",
      "\u001b[0;32m<ipython-input-11-8c73df044e01>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\r\n",
      "\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{cname}:\\n{a}\\n{b}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\r\n",
      "\r\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\r\n",
      "test\r\n",
      "Test\r\n",
      "AssertionError: ==:\r\n",
      "test\r\n",
      "Test\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python run_notebook.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 01 Matrix multiplication (File [01_matmul.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/01_matmul.ipynb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastai\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/25/9a07ca0e7710d97e595dd5b437324fdaeaa6812affeb8d609607e7e022e4/fastai-1.0.50.post1-py3-none-any.whl (212kB)\n",
      "\u001b[K    100% |████████████████████████████████| 215kB 6.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (0.23.4)\n",
      "Requirement already satisfied: torch>=1.0.0 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (1.0.1.post2)\n",
      "Requirement already satisfied: torchvision in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (0.2.2)\n",
      "Collecting nvidia-ml-py3 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/64/cce82bddb80c0b0f5c703bbdafa94bfb69a1c5ad7a79cff00b482468f0d3/nvidia-ml-py3-7.352.0.tar.gz\n",
      "Requirement already satisfied: bottleneck in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (1.2.1)\n",
      "Requirement already satisfied: Pillow in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (5.3.0)\n",
      "Requirement already satisfied: pyyaml in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (3.13)\n",
      "Collecting typing (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (3.0.2)\n",
      "Requirement already satisfied: packaging in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (18.0)\n",
      "Collecting fastprogress>=0.1.19 (from fastai)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/30/01f597392e4e7b4982f387028da941e1fd60a8d53511d17225858d87fb22/fastprogress-0.1.20-py3-none-any.whl\n",
      "Collecting pynvx>=1.0.0; platform_system == \"Darwin\" (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/b7/37ffbba4b792a49e781322b22045f4bbd0fc6598ebf5c07a31a36b52a0b6/pynvx-1.0.0-cp37-cp37m-macosx_10_7_x86_64.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (1.15.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (4.6.3)\n",
      "Requirement already satisfied: numexpr in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (2.6.8)\n",
      "Requirement already satisfied: requests in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from fastai) (2.21.0)\n",
      "Collecting spacy>=2.0.18 (from fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/7f/acc98091fbb1a48e0632558cfbd340d53d7f2b6a6a55b2205ef5ff15f4ca/spacy-2.1.2.tar.gz (27.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 27.7MB 269kB/s eta 0:00:01    48% |███████████████▌                | 13.4MB 26.2MB/s eta 0:00:01    49% |███████████████▉                | 13.7MB 8.4MB/s eta 0:00:02    64% |████████████████████▊           | 17.9MB 6.4MB/s eta 0:00:02\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.0 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from pandas->fastai) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from pandas->fastai) (2018.7)\n",
      "Requirement already satisfied: six in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from torchvision->fastai) (1.12.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from matplotlib->fastai) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from matplotlib->fastai) (2.3.0)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from requests->fastai) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from requests->fastai) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from requests->fastai) (2019.3.9)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/bd/faace403086ee922afc74e5615cb8c21020fcf5d5667314e943c08f71fde/murmurhash-1.0.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/d7/11/37da628920bf2999bd8c4ffc40908413622486d5dbc4e60d87a58c428367/cymem-2.0.2-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/48/fe/2f2e8c91541785f2abe0d51f37eb00356513b9ff3d24fb27fd5b59e18264/preshed-2.0.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting thinc<7.1.0,>=7.0.2 (from spacy>=2.0.18->fastai)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/b1/d7df83813ee3c42d46e6ddf4d4f1d9bd35a4735827d35b7f02539bea3136/thinc-7.0.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (2.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.8MB 4.7MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting blis<0.3.0,>=0.2.2 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/36/41/9e934e2b8a2cdae447ed1923a94f98c2d70c898b65af6635f5fe55f7ed4d/blis-0.2.4-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting plac<1.0.0,>=0.9.6 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from spacy>=2.0.18->fastai) (2.6.0)\n",
      "Collecting wasabi<1.1.0,>=0.2.0 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/09/49/dbfd9a14b0fba9d005a5d02f5164f1316948a3b95f7a96eb159eee5dd646/wasabi-0.2.0-py3-none-any.whl\n",
      "Collecting srsly<1.1.0,>=0.0.5 (from spacy>=2.0.18->fastai)\n",
      "  Using cached https://files.pythonhosted.org/packages/c8/b2/d2cc9f5aa5a458aca45d8689279b41d4b42ba4e8c63b0cb6a9f009340fd0/srsly-0.0.5-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Requirement already satisfied: setuptools in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->fastai) (40.6.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /Users/wittmann/anaconda/envs/udacity-update/lib/python3.7/site-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.0.18->fastai) (4.28.1)\n",
      "Building wheels for collected packages: nvidia-ml-py3, spacy\n",
      "  Running setup.py bdist_wheel for nvidia-ml-py3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/wittmann/Library/Caches/pip/wheels/e4/1d/06/640c93f5270d67d0247f30be91f232700d19023f9e66d735c7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py bdist_wheel for spacy ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/wittmann/Library/Caches/pip/wheels/16/a0/db/765f9fd0fb06694e1292c649fe068a4323004776afedc2180f\n",
      "Successfully built nvidia-ml-py3 spacy\n",
      "Installing collected packages: nvidia-ml-py3, typing, fastprogress, pynvx, murmurhash, cymem, preshed, blis, wasabi, plac, srsly, thinc, spacy, fastai\n",
      "Successfully installed blis-0.2.4 cymem-2.0.2 fastai-1.0.50.post1 fastprogress-0.1.20 murmurhash-1.0.2 nvidia-ml-py3-7.352.0 plac-0.9.6 preshed-2.0.1 pynvx-1.0.0 spacy-2.1.2 srsly-0.0.5 thinc-7.0.4 typing-3.6.6 wasabi-0.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n",
    "- import mnist\n",
    "- extract mnist into train and y valid with numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/wittmann/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _)=pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert numpy arrays to tensor (np is not allowed)\n",
    "- tensor was previoulsy imported from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train,x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get number of columns and rows from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,c = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some visualizations and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_train.shape, y_train, y_train.shape,y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doing some obvious tests from above\n",
    "- img = xtrain\n",
    "- img.view28\n",
    "- plot(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n==y_train.shape[0]==50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(c,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap']='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view(28,28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a24426550>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADgpJREFUeJzt3X+MVfWZx/HPs1j+kKI4aQRCYSnEYJW4082IjSWrxkzVDQZHrekkJjQapn8wiU02ZA3/VNNgyCrslmiamaZYSFpKE3VB0iw0otLGZuKIWC0srTFsO3IDNTjywx9kmGf/mEMzxbnfe+fec++5zPN+JeT+eM6558kNnznn3O+592vuLgDx/EPRDQAoBuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUZc3cmJlxOSHQYO5u1SxX157fzO40syNm9q6ZPVrPawFoLqv12n4zmybpj5I6JQ1Jel1St7sfSqzDnh9osGbs+ZdJetfd33P3c5J+IWllHa8HoInqCf88SX8Z93goe+7vmFmPmQ2a2WAd2wKQs3o+8Jvo0OJzh/Xu3i+pX+KwH2gl9ez5hyTNH/f4y5KO1dcOgGapJ/yvS7rGzL5iZtMlfVvSrnzaAtBoNR/2u/uImfVK2iNpmqQt7v6H3DoD0FA1D/XVtDHO+YGGa8pFPgAuXYQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfMU3ZJkZkclnZZ0XtKIu3fk0RTyM23atGT9yiuvbOj2e3t7y9Yuv/zy5LpLlixJ1tesWZOsP/XUU2Vr3d3dyXU//fTTZH3Dhg3J+uOPP56st4K6wp+5zd0/yOF1ADQRh/1AUPWG3yXtNbM3zKwnj4YANEe9h/3fcPdjZna1pF+b2f+6+/7xC2R/FPjDALSYuvb87n4suz0h6QVJyyZYpt/dO/gwEGgtNYffzGaY2cwL9yV9U9I7eTUGoLHqOeyfLekFM7vwOj939//JpSsADVdz+N39PUn/lGMvU9aCBQuS9enTpyfrN998c7K+fPnysrVZs2Yl173vvvuS9SINDQ0l65s3b07Wu7q6ytZOnz6dXPett95K1l999dVk/VLAUB8QFOEHgiL8QFCEHwiK8ANBEX4gKHP35m3MrHkba6L29vZkfd++fcl6o79W26pGR0eT9YceeihZP3PmTM3bLpVKyfqHH36YrB85cqTmbTeau1s1y7HnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOfPQVtbW7I+MDCQrC9atCjPdnJVqffh4eFk/bbbbitbO3fuXHLdqNc/1ItxfgBJhB8IivADQRF+ICjCDwRF+IGgCD8QVB6z9IZ38uTJZH3t2rXJ+ooVK5L1N998M1mv9BPWKQcPHkzWOzs7k/WzZ88m69dff33Z2iOPPJJcF43Fnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX4z2yJphaQT7r40e65N0g5JCyUdlfSAu6d/6FxT9/v89briiiuS9UrTSff19ZWtPfzww8l1H3zwwWR9+/btyTpaT57f5/+ppDsveu5RSS+5+zWSXsoeA7iEVAy/u++XdPElbCslbc3ub5V0T859AWiwWs/5Z7t7SZKy26vzawlAMzT82n4z65HU0+jtAJicWvf8x81sriRltyfKLeju/e7e4e4dNW4LQAPUGv5dklZl91dJ2plPOwCapWL4zWy7pN9JWmJmQ2b2sKQNkjrN7E+SOrPHAC4hFc/53b27TOn2nHsJ69SpU3Wt/9FHH9W87urVq5P1HTt2JOujo6M1bxvF4go/ICjCDwRF+IGgCD8QFOEHgiL8QFBM0T0FzJgxo2ztxRdfTK57yy23JOt33XVXsr53795kHc3HFN0Akgg/EBThB4Ii/EBQhB8IivADQRF+ICjG+ae4xYsXJ+sHDhxI1oeHh5P1l19+OVkfHBwsW3vmmWeS6zbz/+ZUwjg/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf7gurq6kvVnn302WZ85c2bN2163bl2yvm3btmS9VCrVvO2pjHF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxXF+M9siaYWkE+6+NHvuMUmrJf01W2ydu/+q4sYY57/kLF26NFnftGlTsn777bXP5N7X15esr1+/Pll///33a972pSzPcf6fSrpzguf/093bs38Vgw+gtVQMv7vvl3SyCb0AaKJ6zvl7zez3ZrbFzK7KrSMATVFr+H8kabGkdkklSRvLLWhmPWY2aGblf8wNQNPVFH53P+7u5919VNKPJS1LLNvv7h3u3lFrkwDyV1P4zWzuuIddkt7Jpx0AzXJZpQXMbLukWyV9ycyGJH1f0q1m1i7JJR2V9N0G9gigAfg+P+oya9asZP3uu+8uW6v0WwFm6eHqffv2JeudnZ3J+lTF9/kBJBF+ICjCDwRF+IGgCD8QFOEHgmKoD4X57LPPkvXLLktfhjIyMpKs33HHHWVrr7zySnLdSxlDfQCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIrf50dsN9xwQ7J+//33J+s33nhj2VqlcfxKDh06lKzv37+/rtef6tjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPNPcUuWLEnWe3t7k/V77703WZ8zZ86ke6rW+fPnk/VSqZSsj46O5tnOlMOeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2bzJW2TNEfSqKR+d/+hmbVJ2iFpoaSjkh5w9w8b12pclcbSu7u7y9YqjeMvXLiwlpZyMTg4mKyvX78+Wd+1a1ee7YRTzZ5/RNK/uftXJX1d0hozu07So5JecvdrJL2UPQZwiagYfncvufuB7P5pSYclzZO0UtLWbLGtku5pVJMA8jepc34zWyjpa5IGJM1295I09gdC0tV5Nwegcaq+tt/MvijpOUnfc/dTZlVNByYz65HUU1t7ABqlqj2/mX1BY8H/mbs/nz193MzmZvW5kk5MtK6797t7h7t35NEwgHxUDL+N7eJ/Iumwu28aV9olaVV2f5Wknfm3B6BRKk7RbWbLJf1G0tsaG+qTpHUaO+//paQFkv4s6VvufrLCa4Wconv27NnJ+nXXXZesP/3008n6tddeO+me8jIwMJCsP/nkk2VrO3em9xd8Jbc21U7RXfGc391/K6nci90+maYAtA6u8AOCIvxAUIQfCIrwA0ERfiAowg8ExU93V6mtra1sra+vL7lue3t7sr5o0aKaesrDa6+9lqxv3LgxWd+zZ0+y/sknn0y6JzQHe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOP9NN92UrK9duzZZX7ZsWdnavHnzauopLx9//HHZ2ubNm5PrPvHEE8n62bNna+oJrY89PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EFWacv6urq656PQ4dOpSs7969O1kfGRlJ1lPfuR8eHk6ui7jY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUObu6QXM5kvaJmmOpFFJ/e7+QzN7TNJqSX/NFl3n7r+q8FrpjQGom7tbNctVE/65kua6+wEzmynpDUn3SHpA0hl3f6rapgg/0HjVhr/iFX7uXpJUyu6fNrPDkor96RoAdZvUOb+ZLZT0NUkD2VO9ZvZ7M9tiZleVWafHzAbNbLCuTgHkquJh/98WNPuipFclrXf3581stqQPJLmkH2js1OChCq/BYT/QYLmd80uSmX1B0m5Je9x90wT1hZJ2u/vSCq9D+IEGqzb8FQ/7zcwk/UTS4fHBzz4IvKBL0juTbRJAcar5tH+5pN9IeltjQ32StE5St6R2jR32H5X03ezDwdRrsecHGizXw/68EH6g8XI77AcwNRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCavYU3R9I+r9xj7+UPdeKWrW3Vu1Lorda5dnbP1a7YFO/z/+5jZsNuntHYQ0ktGpvrdqXRG+1Kqo3DvuBoAg/EFTR4e8vePsprdpbq/Yl0VutCumt0HN+AMUpes8PoCCFhN/M7jSzI2b2rpk9WkQP5ZjZUTN728wOFj3FWDYN2gkze2fcc21m9msz+1N2O+E0aQX19piZvZ+9dwfN7F8L6m2+mb1sZofN7A9m9kj2fKHvXaKvQt63ph/2m9k0SX+U1ClpSNLrkrrd/VBTGynDzI5K6nD3wseEzexfJJ2RtO3CbEhm9h+STrr7huwP51Xu/u8t0ttjmuTMzQ3qrdzM0t9Rge9dnjNe56GIPf8ySe+6+3vufk7SLyStLKCPlufu+yWdvOjplZK2Zve3auw/T9OV6a0luHvJ3Q9k909LujCzdKHvXaKvQhQR/nmS/jLu8ZBaa8pvl7TXzN4ws56im5nA7AszI2W3Vxfcz8UqztzcTBfNLN0y710tM17nrYjwTzSbSCsNOXzD3f9Z0l2S1mSHt6jOjyQt1tg0biVJG4tsJptZ+jlJ33P3U0X2Mt4EfRXyvhUR/iFJ88c9/rKkYwX0MSF3P5bdnpD0gsZOU1rJ8QuTpGa3Jwru52/c/bi7n3f3UUk/VoHvXTaz9HOSfubuz2dPF/7eTdRXUe9bEeF/XdI1ZvYVM5su6duSdhXQx+eY2YzsgxiZ2QxJ31TrzT68S9Kq7P4qSTsL7OXvtMrMzeVmllbB712rzXhdyEU+2VDGf0maJmmLu69vehMTMLNFGtvbS2PfePx5kb2Z2XZJt2rsW1/HJX1f0n9L+qWkBZL+LOlb7t70D97K9HarJjlzc4N6Kzez9IAKfO/ynPE6l364wg+IiSv8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E9f/Ex0YKZYOZcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Initial python model\n",
    "- wights receives random values 784 in and 10 out\n",
    "- bias initialized with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.randn(784,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias=torch.zeros(10);bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication pseudocode\n",
    "- function of matrix multiplication\n",
    "- review of matrix multiplication from matrixmultiplication.xyz\n",
    "    - A few loops going on: three\n",
    "- def matmul\n",
    "- ar and ac receive shape of matrix a\n",
    "- br and bc receives shape of matrix be\n",
    "-  assert the shapes of ac and br are the same\n",
    "- c receives zeros with shape ar and br\n",
    "- for i in range ar\n",
    "    - for j in range\n",
    "        - for k in range(ac):\n",
    "            - c(i,j)...\n",
    "\n",
    "- m1 receives x_validation\n",
    "- m2 receives weights\n",
    "- time the usage of matrix multiplication\n",
    "    - result 800ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac):\n",
    "                c[i,j]+=a[i,k]*b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=x_valid[:5]\n",
    "m2=weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 979 ms, sys: 5.9 ms, total: 984 ms\n",
      "Wall time: 990 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **the multiplication is quite slow. Let's try to speed it up**\n",
    "    - Every layer would take about 10 hours\n",
    "    - That's why we don't write things on pure python\n",
    "    - Let's try to speed this up\n",
    "    - Let's pass the backend to pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise operations\n",
    "- a receives a tensor\n",
    "- b receives another nesor\n",
    "- sum both tensors\n",
    "- a less tham b conveted to a float and get their mean\n",
    "- m receives a tensor matrix\n",
    "- **calculate frobenius norm**\n",
    "- trying to translate equations into code\n",
    "- sum is two for loops, one in i and other in j\n",
    "- square of the sum of all the terms\n",
    "- Howard dont write latex :)\n",
    "    - He copy and paste from google wikipedia\n",
    "- m times m sum and sware root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  5., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tensor([10., 5, -4])\n",
    "b=tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 13.,  3.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a<b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tensor([[1.,2,3],[4,5,6],[7,8,9]]);m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fobenius norm:\n",
    "$$||A||_F = (\\sum_{i,j=1}^{n}|a_{i,j}|^2)^{1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise matmul\n",
    "- replace third loop with frobenius norm\n",
    "- c = a_i + b_j . sum\n",
    "- time is 700 faster\n",
    "- backend in C\n",
    "- let's check if it is right\n",
    "- define function near(a,b) using torch. allclose()\n",
    "- test_near receives test(near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            c[i,j]=(a[i,:]*b[:,j]).sum()\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.63 ms ± 597 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'603.68 times faster'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{984/1.63:.2f} times faster'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b):\n",
    "    return torch.allclose(a,b,rtol=1e-3,atol=1e-5)\n",
    "\n",
    "def test_near(a,b):\n",
    "    test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's get rid of one more loop\n",
    "\n",
    "#### Broadcasting\n",
    "- run at cuda\n",
    "- remove loops\n",
    "- describes how arrays with differents shapes are treated during arithmetic operations\n",
    "- first used in numpy\n",
    "- is like a new programming language\n",
    "- a > 0 comparing tensor with value, it works because of 0 is being broadcast to have same dimension as a\n",
    "- a+1 also broadcast 1 to the tensor a\n",
    "- 2*m broadcasts 2 to tm\n",
    "\n",
    "- **broadcast with a scalar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  5., -4.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we able to do a>0? 0 is bein broadcast to have the same dimensions as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.,  6., -3.])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.],\n",
       "        [14., 16., 18.]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting a vector to a matrix\n",
    "- c receives a tensor\n",
    "- m and c have different shapes (3x3) and (3x1)\n",
    "- array is broadcasted to\n",
    "- theres no loop but it looks like as there was a loop\n",
    "- c.expand_as(m)\n",
    "- version of c as a broadcast tensor rank 2 instead of array\n",
    "- c speed with no looop\n",
    "- t.storashe show sthat thers onl 3 values bein stored\n",
    "- b.stride()\n",
    "- tensor behave like higher rank things\n",
    "\n",
    "what if we want to take a column instead fo a row?\n",
    "- c.unsqueeze(0j=) is a shape one comma 3\n",
    "- c.unsqueeze 1 is a shape three coma one\n",
    "- this is interesting because\n",
    "- c none columns is is same shape 1 and c : none is same of squeeze 1\n",
    "- c[:, None].expand as m broadcast as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]);c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c+m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really copy the rows, but it looks as if we did. In fcat, the rows are given a stride of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = c.expand_as(m);t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Review of Rank:** The rank of a matrix A is the dimension of the vector space generated by its columns. Corresponde to the maximal number of linearly independent columns of A. For example:\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1bf2b250d0de299673e8a5538de6e7a9eeb74e42\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -4.005ex; width:15.601ex; height:9.176ex;\" alt=\"{\\displaystyle {\\begin{bmatrix}1&amp;0&amp;1\\\\-2&amp;-3&amp;1\\\\3&amp;3&amp;0\\end{bmatrix}}}\">\n",
    "\n",
    "has rank 2: the first two columns are linearly independent, so the rank is at least 2, but since the third is a linear combination of the first two (the second subtracted from the first (the second subtracted from the first), the three columns are linearly dependent so the rank must be less than 3.\n",
    "\n",
    "The matrix\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/fa97694618119aeec3bc66382bc7219d052beaff\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.505ex; width:25.09ex; height:6.176ex;\" alt=\"A=\\begin{bmatrix}1&amp;1&amp;0&amp;2\\\\-1&amp;-1&amp;0&amp;-2\\end{bmatrix}\">\n",
    "\n",
    "has rank 1: there are nonzero columns, so the rank is positive, but any pair of colums is linearly dependent. Also $A^T$ has always the same rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10., 20., 30.]), tensor([[10., 20., 30.]]))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, c.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c.unsqueeze(0).shape, c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of using unqueeze, we can use None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10., 20., 30.]), tensor([[10., 20., 30.]]), tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, c[None, :], c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c[None, :].shape, c[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 1])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None, None, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].shape, c[...,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[...,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [24., 25., 26.],\n",
       "        [37., 38., 39.]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m+c[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in Excel\n",
    "- semicol and none is column and note afer is row\n",
    "\n",
    "### Eliminating loops with broadcasting\n",
    "- The entire row of c[i] (which is c i : (you can eliminate the semicolomns)\n",
    "- ci receives row i of a. unsqueeze (-1) which is the last dimension\n",
    "- you can also write a, i None instad of -1\n",
    "- rank 2 tensor and b is also a rank 2 tensor. unsqueeze to broadcast into b and then sum them over the rows (dim 0)\n",
    "- **Homework:** Why this works??\n",
    "\n",
    "\n",
    "- 3200 faster now with broadcasting\n",
    "- getting rid of looops also reduces errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "    #    for j in range(bc):\n",
    "    #        c[i,j]=(a[i,:]*b[:,j]).sum()\n",
    "        c[i,:] = (a[i].unsqueeze(-1)*b).sum(dim=0)\n",
    "        c[i]=(a[i,None]*b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274 µs ± 53.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.95 faster than previous'"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{1630/274:.2f} faster than previous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework \n",
    "- [x] **HOMEWORK:** Convince yourself on why ` c[i]=(a[i,None]*b).sum(dim=0)` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [2., 3., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5.],\n",
       "        [6., 7.],\n",
       "        [1., 8.]])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking two matrices from matrixmultplication.xyz\n",
    "a = tensor([[1.,2,1],[0,1,0],[2,3,4]]);print(a)\n",
    "b = tensor([[2.,5],[6,7],[1,8]]);b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar,ac=a.shape #nrows * ncols\n",
    "br,bc=b.shape\n",
    "c=torch.zeros(ar,bc)\n",
    "list(range(ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 2)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar, ac, br, bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first manually iterate\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets debug (a[i].unsqueeze(-1)*b).sum(dim=0)\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[i].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5.],\n",
       "        [6., 7.],\n",
       "        [1., 8.]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  5.],\n",
       "        [12., 14.],\n",
       "        [ 1.,  8.]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[i].unsqueeze(-1)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15., 27.])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7., 26.,  9.])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 7.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add one more iteration\n",
    "i=1\n",
    "(a[i].unsqueeze(-1)*b).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 27.],\n",
       "        [ 6.,  7.],\n",
       "        [26., 63.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected answer\n",
    "matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting rules\n",
    "- c[None, :] is row based\n",
    "- shape 1 by 3\n",
    "- eleentwise multiplication\n",
    "- c times c[:, none] value by value matrix\n",
    "- broadcast into squared\n",
    "- they dont have to be in the same rank\n",
    "- you can normalize by channel with no limnes of code\n",
    "- **Class Break**\n",
    "  - Goal make code faster\n",
    "  - how to do our own stuff\n",
    "  - how to write codes fast\n",
    "  - broadcast trick is one of the best for making loops fater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30])\n",
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 200., 300.],\n",
       "        [200., 400., 600.],\n",
       "        [300., 600., 900.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]*c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None]>c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When operating on two arrays/tensors, Numpy/PyTroch compares their shapes element-wise. It satarts with the trailing dimensions, and works its way foward. Two dimensions are compatible when\n",
    "- They are equal, or\n",
    "- One of them is 1, in whic case that dimension is broadcasted to make it the same size\n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a $256*256*3$ array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein summation\n",
    "- Popularized by einsteing for higher rank matrix\n",
    "- Compact representation for combining products and sums in a general way\n",
    "- if pytorch didnt have batchwise multiplication, noe new index oadded would transform it\n",
    "- c i j + a i k times b , j\n",
    "- a i k k j -> i j\n",
    "    - using index inside string for notation and matrix\n",
    "- def matmul(a,b) return torch.einsum('ik,kj->ij', a, b)\n",
    "- now it is 16 times faster using einstein sum\n",
    "- tragedy that it exists\n",
    "- a programming language using string\n",
    "- amazing but so few things it does\n",
    "- I want to generalize to a language\n",
    "- hope is that swift give ability to write stuffs that really fast\n",
    "- swift is even faster than einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac):\n",
    "                c[i,j]+=a[i,k]*b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# c[i,j]+=a[i,k]*b[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# [i,j]+=[i,k]*[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# [i,k]*[k,j]->[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# ik,kj->ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.4 µs ± 17.7 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.09 faster than previous'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{274/67:.2f} faster than previous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14776.12 faster than first attempt'"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{990e3/67:.2f} faster than first attempt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch operator\n",
    "- use pytorchs function or operator directly for matrix multiplication\n",
    "- 50 thousand faster\n",
    "- m1.matmul\n",
    "- divide into batches, written into assemb, blal, library of linear algebra, for example cuBlAS\n",
    "- awfaw, bc program is limited to a subset of thinks that BLAS can write read\n",
    "- limited to python methods\n",
    "- people working on this on swift\n",
    "- facebook research and tensor compresions\n",
    "- in python we are restricted to m1.matmul\n",
    "- pure ehanced way with einsum is 10 thousand slower\n",
    "- need of libraries\n",
    "- t2 = m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.9 µs ± 6.87 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 faster than previous\n",
      "58235.29 faster than first attempt\n"
     ]
    }
   ],
   "source": [
    "print(f'{67/17.9:.2f} faster than previous')\n",
    "print(f'{990e3/17:.2f} faster than first attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using as default for matrix multiplication\n",
    "\n",
    "## [1:23:00](https://youtu.be/4u8FxNEDUeg?t=5002) Notebook 02 Fully Connected Layers (file [02_fully_connected.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/02_fully_connected.ipynb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The foward and backward passes\n",
    "- x train, y train, x y get data\n",
    "- get standard deviation\n",
    "- normalize using standard deviation\n",
    "- note use training, not validation mean for normalizing validation set\n",
    "- afer doing that mean is close to zero and std close to 1\n",
    "- test function if it is really normalized\n",
    "- n,m get xtrain shape\n",
    "- c output size\n",
    "\n",
    "Defining the model\n",
    "\n",
    "- Model has one hidden layer\n",
    "- Foundations version\n",
    "- basic architecture\n",
    "- number of hidden layers  nhis 50\n",
    "- two layers is two wegiths and biases matrices\n",
    "- w1 is random values divided by sqare root of m\n",
    "- b are zeros\n",
    "- w2 is random values (nh,1) divided by math sqarue of nh\n",
    "- t is linear of three vectors\n",
    "- divide by sqare root m then tensor has lower values\n",
    "- simplified kaiming initialization, wrote a paper about it\n",
    "- test mean and standard of weight 1\n",
    "- thing that really matters when training\n",
    "\n",
    "- **[1] Fixup initialization:** https://arxiv.org/abs/1901.09321\n",
    "    - paper with 10000 layers just with careful initialization\n",
    "- how initialization is made really matters\n",
    "- spend a lot of time on this in depth\n",
    "- first layer is defined by relu\n",
    "- relu is grag data and clamp min to z (replace negative to zero)\n",
    "- try to find the function internal on pytorch\n",
    "\n",
    "- unfortunatelly does not have mean zero and std of 1\n",
    "\n",
    "- demonstration\n",
    "    - distribution of data\n",
    "    - then took evertyhing smaller and took out\n",
    "    - obviously mean and std are gong to differ\n",
    "![Screen Shot 2019-03-19 at 11 29 08](https://user-images.githubusercontent.com/5733246/54631965-46545000-4a3a-11e9-82bc-c27e7c59dff8.png)\n",
    "\n",
    "- **[2] Surpassing human level performance on imagenet classification**: https://arxiv.org/abs/1502.01852\n",
    "    - > one of the most extraordinary papers in the last few years\n",
    "    - full of great ideas\n",
    "    - read papers from competition winners if a great idea\n",
    "    - where competition ideas has 20 good\n",
    "    - kine initialization\n",
    "    - Section 2.2 initialization of filter weights for rectifiers\n",
    "    - are easier to train cbut a bat initializatiom still hamper the learning of a non linear system\n",
    "    - initializet with random gaussian distributions\n",
    "    - glorot and benchi proposded a new initialization\n",
    "\n",
    "- **[3] Understanding the difficulty of training deep feedforward neural networks**: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "    - Very readable and practible\n",
    "    - well be reimplementing stuffs from the paper\n",
    "    - Final result solution is simple\n",
    "    - **One suggestion is another approach called normalized initialization**\n",
    "        - Based on the square root\n",
    "\n",
    "- [2](https://arxiv.org/abs/1502.01852) pointed out that the initializatoin does not account for relu\n",
    "    - super simple solution is to replace the one in the top to a two in the top of the initializaton\n",
    "    - $$std = sqrt(2/((1+a^2) * fan_in))$$\n",
    "    - closer to std 1 and mean zero\n",
    "\n",
    "- **!!HOMEWORK: Read 2.2 of [2](https://arxiv.org/abs/1502.01852)**\n",
    "\n",
    "#### Foward propagation layer\n",
    "\n",
    "take it throuh step by step.\n",
    "6 paragraphs to read\n",
    "!! read section foward\n",
    "> \"this leads to a zero-mean gaussian distribution whose standar deviation\"\n",
    "\n",
    "something new and obvious is to replace relu to x.clamp_min(0)-0.5 which will return to the correct mean\n",
    "\n",
    "he had to add a mode callsed fan out\n",
    "- fan ipreserves the magnitudes in the output pass\n",
    "    - Dividing by the fifrst or second\n",
    "- we need it because the weights shape is 784 by 50 while a linear torch is 50 by 784\n",
    "- look into source code to undertand using double question mark\n",
    "- it calls F.linear (F.nn.functional)\n",
    "- letds look\n",
    "- a linear layer with their transposed\n",
    "- thats why we gave the oposite when compared to torch code\n",
    "\n",
    "what about conv layers??\n",
    "\n",
    "check documentation\n",
    "mostly documentation\n",
    "mostly code is under $_ConvND$_\n",
    "at the very bottong theres the file conv\n",
    "it has a special multiplier math.sqrt(5)\n",
    "seem to work pretty badly\n",
    "always a good idea to add comment\n",
    "- feeling that this is not great\n",
    "- we desined our own activation function\n",
    "- of relu minus 0.5\n",
    "- using it the mean is almost zero and variance is almost one\n",
    "- make sense why this makes better results\n",
    "\n",
    "Doing a foward pass\n",
    "\n",
    "def model\n",
    "linear layer\n",
    "relu\n",
    "linear layer\n",
    "\n",
    "time it\n",
    "test\n",
    "\n",
    "#### Loss function: MSE\n",
    "- simplify thinkgs using mean square error\n",
    "- expect a single vector\n",
    "- use squeze to get rid in output.squeeze()\n",
    "- very common broke code because squeeze into a scaler\n",
    "better to put dimension in squeeze (-1) for example\n",
    "y train, y validation get floats\n",
    "\n",
    "get the mean squared error\n",
    "\n",
    "### Gradients and backward pass\n",
    "- paper the matrix calculus you need for deep learning html by jeremy howard and terence parr: https://explained.ai/matrix-calculus/index.html\n",
    "\n",
    "> all you need to know is the chain rule\n",
    "\n",
    "start with an input, then a linear layer then a relu then second linear layer, then mse then y pred\n",
    "\n",
    "other way is\n",
    "y_pred = mse(lin2(relu(lin1(x))),y)\n",
    "\n",
    "we want the gradient of the ouput y with the respect of the input x\n",
    "\n",
    "y equals to f(u)\n",
    "u equals to f(x)\n",
    "derivatie dy/dx is dy/dy times du/dx\n",
    "thats all you need to know\n",
    "\n",
    "usually iti is not treated as division, but yo actually you cant\n",
    "defivatinve is taking some fuction\n",
    "dividing small change in y by small change in x\n",
    "\n",
    "start with mean squared error\n",
    "gradient of the loss with respect to outputprevious layer\n",
    "\n",
    "it is two times error\n",
    "\n",
    "def mse_grad(input, target)\n",
    "\n",
    "the input of mse is the output of previous layer\n",
    "\n",
    "def gradient of relu\n",
    "\n",
    "either zero or 1 which is inp > 0 dot float times out.g\n",
    "\n",
    "linear gradient defined\n",
    "\n",
    "\n",
    "def foward and backward\n",
    "\n",
    "in backward pass\n",
    "mse_grad\n",
    "lin_grad\n",
    "relu_grad\n",
    "\n",
    "value inp.g is updated in each function\n",
    "\n",
    "loss is the mse we never use it\n",
    "\n",
    "the loss never appears in the gradients\n",
    "\n",
    "so w1.g w2.g ans so on contain the gradients\n",
    "\n",
    "let's clone weights and biases and test them\n",
    "\n",
    "we cheat a little bit and use pytorch autograd required grad to check our results\n",
    "\n",
    "using test near to check if results are correct\n",
    "\n",
    "### Layers as classes\n",
    "Refactory\n",
    "- recreating pytorch api\n",
    "\n",
    "class Relu()\n",
    "    def __call__ # treat relu as a function and call whats inside\n",
    "    safe input and outpu\n",
    "    def backpro self.inp.g = self.float.self.out\n",
    "\n",
    "\n",
    "for linear compute self.w.g in backward\n",
    "\n",
    "** backward always compute .g**\n",
    "\n",
    "Class model\n",
    "\n",
    "\n",
    "init has w1, b1, w2, b2\n",
    "\n",
    "def call with x and target\n",
    "\n",
    "def backwar with self.loss.backward() to save loss.g\n",
    "\n",
    "w1.g, b1.g w2.g\n",
    "model =\n",
    "\n",
    "However, that was slow!!\n",
    "\n",
    "### Module foward\n",
    "\n",
    "create a new def in module callde forward which initially raise not implemented\n",
    "\n",
    "class Relu(module)\n",
    "it used foward\n",
    "\n",
    "the thing to calculate the gradient with the respect to the weights, we can reexpress that with einsum\n",
    "now it is faster with einsum\n",
    "\n",
    "time it now is 143ms intesad of 3s\n",
    "\n",
    "> This is why we have to use those modules\n",
    "\n",
    "#### Without einsum\n",
    "\n",
    "repplace with matrix multiplication\n",
    "140ms\n",
    "\n",
    "implemented nn.linear\n",
    "\n",
    "#### nn linear and nn.module\n",
    "even faster\n",
    "\n",
    "?? So, does pytorch uses or not autograd?\n",
    "\n",
    "### Next lesson\n",
    "train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
