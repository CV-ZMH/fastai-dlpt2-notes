{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Part II: Deep Learning from the Foundations\n",
    "\n",
    "> *NOTE: The document is mostly made from notes that I typed while in the class, that's why it is messy sometimes. It is a work in progress. When watching the videos I will be continuously updating the notes.*\n",
    "\n",
    "## Intro\n",
    "- Very different part II of previous year\n",
    "- We will implement fastai library from foundations (from scratch)\n",
    "    - Basic matrix calculus\n",
    "    - Training loops\n",
    "    - Optimizers customized\n",
    "    - Customized annealing\n",
    "    - Actually something where you can train world class models\n",
    "- Read and implement papers\n",
    "- Solve applications that are not fully backed in the fastai library\n",
    "- In the end, implement on Swift\n",
    "- So many papers nowaday\n",
    "    - and says minor variations of the same thing\n",
    "- Show the foundations so that you can choose your 12 papers\n",
    "- Cutting edge is really about engineer, not about papers\n",
    "    - Who can bake that things in code\n",
    "- Part II will be more about bottom up (with code)\n",
    "- Create your own algorithm to solve the things you do.\n",
    "- Today we'll implement matrix multiplication from scratch with Python\n",
    "\n",
    "## Embracing Swift for Deep Learning\n",
    "- Chris\n",
    "    - Built compilers, C for Mac\n",
    "    - Built the most recent language\n",
    "    - Currently dedicating his life to deep learning\n",
    "- Julia has pottential as well!\n",
    "- S4TF Pros\n",
    "    - Write everything in swift\n",
    "    - See whats happening\n",
    "    - opportunities\n",
    "- Cons\n",
    "    - Minimal Ecosystem\n",
    "    - Very little works\n",
    "    - Lots to learn\n",
    "- PyTorch Pros\n",
    "    - Get work done now\n",
    "    - Great ecosystem\n",
    "    - Docs and tutorials\n",
    "- Cons\n",
    "    - Performance\n",
    "    - Pythons types\n",
    "    - Mismatch with backend libs\n",
    "- Swift will possibibly take place in this field\n",
    "\n",
    "## What do we mean by from the foudations?\n",
    "Recreate fastai and much of pytorch? matrix multiply, torch.nn, using:\n",
    "- Python\n",
    "- Python stdlib\n",
    "- Non ds modules\n",
    "- Pytorch array creation, RGN, indexer\n",
    "- fastai.datasets\n",
    "- matplotlib\n",
    "\n",
    "## But why?\n",
    "- Really experiment\n",
    "- Understand it by creating it\n",
    "- Correlate papers with code\n",
    "- Tweak everythin\n",
    "- Contribute\n",
    "\n",
    "## There are many opportunities in this class\n",
    "- Your homework will be at the cutting edge\n",
    "- Few DL practictioners know what you know now\n",
    "- Experiment lots, especially in your area of expertise\n",
    "- Much of what you find will have not be written about before\n",
    "- Don't wait to be perfect before you start communicating\n",
    "    - > Write stuff down for the You of 6 months ago, that's your audience\n",
    "- If you don't have a blog, try medium.com\n",
    "\n",
    "## Recap of part I\n",
    "- He assumes that you don't remember everything.\n",
    "- As we go on, if necessary, you go back and watch that video\n",
    "- Especially the second half\n",
    "- He assumes that you know know about SGD from the scratch\n",
    "- Topics\n",
    "    - Convolutions\n",
    "    - Weight decay\n",
    "    - Dropout\n",
    "    - ...\n",
    "\n",
    "## Overfit > Reduce overfitting > There's no step 3\n",
    "- Try to make sure we can train good models\n",
    "- There are ~~three~~two steps for trainig a good model\n",
    "1. First we try to create something with way more capacity than we need\n",
    "    - No regularization\n",
    "    - Overfit\n",
    "2. Overfitting does not mean training loss lower than validation loss\n",
    "    - A wealthy model almost always will have such behavior\n",
    "    - **Overfitting is when you actually see your validation loss getting worse**\n",
    "- Possible three would be visualize output\n",
    "- One is easy, the two is more difficult.\n",
    "\n",
    "## Five steps to avoid overfitting\n",
    "1. More data\n",
    "2. Data augmentation\n",
    "3. Generalizable architectures\n",
    "4. Regularization\n",
    "5. Reduce archtecture complexity\n",
    "\n",
    "- Most begginers start with 5 but that should be the last\n",
    "    - Unless the model is too slow\n",
    "\n",
    "## It's time to start reading papers\n",
    "- Even familiar stuff look complex in a paper!\n",
    "- Papers are important for deep learning beyond the basics, but hard to read\n",
    "- Google for a blog post describing the paper\n",
    "    - They are not selected for their outstanding clarity of comunication\n",
    "    - Usually a blog post will do the job way better than the paper does\n",
    "- Learn to produce greek letters\n",
    "\n",
    "\n",
    "## List of mathematical symbols on Wikipedia\n",
    "- https://en.wikipedia.org/wiki/List_of_mathematical_symbols\n",
    "- or use [detexify](http://detexify.kirelabs.org/classify.html)\n",
    "\n",
    "# In the next couple of lessons\n",
    "\n",
    "## Steps to a basic modern CNN model\n",
    "> We are going to create a pretty confident modern CNN model\n",
    "\n",
    "- Matmul\n",
    "- Relu/init\n",
    "- Fully Connected foward\n",
    "- Fully Connected backward\n",
    "- Train loop\n",
    "- Conv\n",
    "- Optim\n",
    "- Batch-norm\n",
    "- Resnet\n",
    "    - We already have this last one from Part 1\n",
    "\n",
    "**Goal of today's class**\n",
    "- Go from matrix multiplication to backward pass\n",
    "\n",
    "## [Lesson 00.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/00_exports.ipynb)\n",
    "- How to buld an app on jupyter notebooks\n",
    "- More productive on Jupyter notebooks\n",
    "\n",
    "### How to pull out bits of code from jupyter into a package\n",
    "- Use the special comment `#export` to tell the system a cell that you want to keep and reuse.  \n",
    "- Then use the file [`notebook2script.py`](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/notebook2script.py) which goes through the program and find cells with the special comment `#export` and put them into a python module.\n",
    "    - Path.stem.split(\"-\") is used for the output filename, hence, the output name is the first portion before an undesrcore. If there's no underscore, then the full name.\n",
    "    - The exported module goes to a folder called `exp`\n",
    "- We can then import the exported module using `from exp.nb_00 import *`\n",
    "- Creating a test framework\n",
    "    - `test` and `test_eq` using `assert`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "TEST = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  1078  100  1078    0     0   4967      0 --:--:-- --:--:-- --:--:--  4967\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fastai/fastai_docs/master/dev_course/dl2/notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "import json,fire,re\r\n",
      "from pathlib import Path\r\n",
      "\r\n",
      "def is_export(cell):\r\n",
      "    if cell['cell_type'] != 'code': return False\r\n",
      "    src = cell['source']\r\n",
      "    if len(src) == 0 or len(src[0]) < 7: return False\r\n",
      "    #import pdb; pdb.set_trace()\r\n",
      "    return re.match(r'^\\s*#\\s*export\\s*$', src[0], re.IGNORECASE) is not None\r\n",
      "\r\n",
      "def notebook2script(fname):\r\n",
      "    fname = Path(fname)\r\n",
      "    fname_out = f'nb_{fname.stem.split(\"_\")[0]}.py'\r\n",
      "    main_dic = json.load(open(fname,'r'))\r\n",
      "    code_cells = [c for c in main_dic['cells'] if is_export(c)]\r\n",
      "    module = f'''\r\n",
      "#################################################\r\n",
      "### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\r\n",
      "#################################################\r\n",
      "# file to edit: dev_nb/{fname.name}\r\n",
      "\r\n",
      "'''\r\n",
      "    for cell in code_cells: module += ''.join(cell['source'][1:]) + '\\n\\n'\r\n",
      "    # remove trailing spaces\r\n",
      "    module = re.sub(r' +$', '', module, flags=re.MULTILINE)\r\n",
      "    open(fname.parent/'exp'/fname_out,'w').write(module[:-2])\r\n",
      "    print(f\"Converted {fname} to {fname_out}\")\r\n",
      "\r\n",
      "if __name__ == '__main__': fire.Fire(notebook2script)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat notebook2script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: exp: File exists\r\n"
     ]
    }
   ],
   "source": [
    "mkdir exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted lesson-8-jupyter.ipynb to nb_lesson-8-jupyter.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "d=json.load(open('lesson-8-jupyter.ipynb', 'r'))['cells']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_type': 'code',\n",
       " 'execution_count': 1,\n",
       " 'metadata': {},\n",
       " 'outputs': [],\n",
       " 'source': ['#export\\n', \"TEST = 'test'\"]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv exp/nb_lesson-8-jupyter.py exp/nb_00.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_00 import *\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f'{cname}:\\n{a}\\n{b}'\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_eq(a,b): \n",
    "    test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp=operator.eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eq'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmp.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use [`run_notebook.py`](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/run_notebook.py) to run the tests outside of the jupyter notebook\n",
    "    - `python run_notebook.py 01_matmul.ipynb` run the tests outside of the jupyter notebook\n",
    "    - We can see the assertion error when running in the terminal\n",
    "- Now we have an automatable unit test framework on jupyter notebook\n",
    "- Fire to execute a function\n",
    "    - **It takes any function and automatically converts into a command-line interface**\n",
    "    - Inputs of a function are converted into arguments in the command-line\n",
    "- Notebooks are json files.\n",
    "    - We can import cells and play around jupyter notebook files converting them to json files\n",
    "    - Example: `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   319  100   319    0     0    471      0 --:--:-- --:--:-- --:--:--   471\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://raw.githubusercontent.com/fastai/fastai_docs/master/dev_course/dl2/run_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/usr/bin/env python\r\n",
      "\r\n",
      "import nbformat,fire\r\n",
      "from nbconvert.preprocessors import ExecutePreprocessor\r\n",
      "\r\n",
      "def run_notebook(path):\r\n",
      "    nb = nbformat.read(open(path), as_version=nbformat.NO_CONVERT)\r\n",
      "    ExecutePreprocessor(timeout=600).preprocess(nb, {})\r\n",
      "    print('done')\r\n",
      "\r\n",
      "if __name__ == '__main__': fire.Fire(run_notebook)\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!cat run_notebook.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\r\n"
     ]
    }
   ],
   "source": [
    "#!python run_notebook.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 01 Matrix multiplication (File [01_matmul.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/01_matmul.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data\n",
    "- import mnist\n",
    "- extract mnist into train and y valid with numpy arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "from fastai import datasets\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/wittmann/.fastai/data/mnist.pkl.gz')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=datasets.download_data(MNIST_URL, ext='.gz'); path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(path, 'rb') as f:\n",
    "    ((x_train, y_train), (x_valid, y_valid), _)=pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- convert numpy arrays to tensor (np is not allowed)\n",
    "- tensor was previoulsy imported from pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = map(tensor, (x_train, y_train,x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- get number of columns and rows from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,c = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Some visualizations and stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([50000, 784]),\n",
       " tensor([5, 0, 4,  ..., 8, 4, 8]),\n",
       " torch.Size([50000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_train.shape, y_train, y_train.shape,y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Doing some obvious tests from above\n",
    "- img = xtrain\n",
    "- img.view28\n",
    "- plot(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert n==y_train.shape[0]==50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(c,28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap']='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view(28,28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a29c43a58>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADgpJREFUeJzt3X+MVfWZx/HPs1j+kKI4aQRCYSnEYJW4082IjSWrxkzVDQZHrekkJjQapn8wiU02ZA3/VNNgyCrslmiamaZYSFpKE3VB0iw0otLGZuKIWC0srTFsO3IDNTjywx9kmGf/mEMzxbnfe+fec++5zPN+JeT+eM6558kNnznn3O+592vuLgDx/EPRDQAoBuEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxDUZc3cmJlxOSHQYO5u1SxX157fzO40syNm9q6ZPVrPawFoLqv12n4zmybpj5I6JQ1Jel1St7sfSqzDnh9osGbs+ZdJetfd33P3c5J+IWllHa8HoInqCf88SX8Z93goe+7vmFmPmQ2a2WAd2wKQs3o+8Jvo0OJzh/Xu3i+pX+KwH2gl9ez5hyTNH/f4y5KO1dcOgGapJ/yvS7rGzL5iZtMlfVvSrnzaAtBoNR/2u/uImfVK2iNpmqQt7v6H3DoD0FA1D/XVtDHO+YGGa8pFPgAuXYQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVfMU3ZJkZkclnZZ0XtKIu3fk0RTyM23atGT9yiuvbOj2e3t7y9Yuv/zy5LpLlixJ1tesWZOsP/XUU2Vr3d3dyXU//fTTZH3Dhg3J+uOPP56st4K6wp+5zd0/yOF1ADQRh/1AUPWG3yXtNbM3zKwnj4YANEe9h/3fcPdjZna1pF+b2f+6+/7xC2R/FPjDALSYuvb87n4suz0h6QVJyyZYpt/dO/gwEGgtNYffzGaY2cwL9yV9U9I7eTUGoLHqOeyfLekFM7vwOj939//JpSsADVdz+N39PUn/lGMvU9aCBQuS9enTpyfrN998c7K+fPnysrVZs2Yl173vvvuS9SINDQ0l65s3b07Wu7q6ytZOnz6dXPett95K1l999dVk/VLAUB8QFOEHgiL8QFCEHwiK8ANBEX4gKHP35m3MrHkba6L29vZkfd++fcl6o79W26pGR0eT9YceeihZP3PmTM3bLpVKyfqHH36YrB85cqTmbTeau1s1y7HnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOfPQVtbW7I+MDCQrC9atCjPdnJVqffh4eFk/bbbbitbO3fuXHLdqNc/1ItxfgBJhB8IivADQRF+ICjCDwRF+IGgCD8QVB6z9IZ38uTJZH3t2rXJ+ooVK5L1N998M1mv9BPWKQcPHkzWOzs7k/WzZ88m69dff33Z2iOPPJJcF43Fnh8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqr4fX4z2yJphaQT7r40e65N0g5JCyUdlfSAu6d/6FxT9/v89briiiuS9UrTSff19ZWtPfzww8l1H3zwwWR9+/btyTpaT57f5/+ppDsveu5RSS+5+zWSXsoeA7iEVAy/u++XdPElbCslbc3ub5V0T859AWiwWs/5Z7t7SZKy26vzawlAMzT82n4z65HU0+jtAJicWvf8x81sriRltyfKLeju/e7e4e4dNW4LQAPUGv5dklZl91dJ2plPOwCapWL4zWy7pN9JWmJmQ2b2sKQNkjrN7E+SOrPHAC4hFc/53b27TOn2nHsJ69SpU3Wt/9FHH9W87urVq5P1HTt2JOujo6M1bxvF4go/ICjCDwRF+IGgCD8QFOEHgiL8QFBM0T0FzJgxo2ztxRdfTK57yy23JOt33XVXsr53795kHc3HFN0Akgg/EBThB4Ii/EBQhB8IivADQRF+ICjG+ae4xYsXJ+sHDhxI1oeHh5P1l19+OVkfHBwsW3vmmWeS6zbz/+ZUwjg/gCTCDwRF+IGgCD8QFOEHgiL8QFCEHwiKcf7gurq6kvVnn302WZ85c2bN2163bl2yvm3btmS9VCrVvO2pjHF+AEmEHwiK8ANBEX4gKMIPBEX4gaAIPxBUxXF+M9siaYWkE+6+NHvuMUmrJf01W2ydu/+q4sYY57/kLF26NFnftGlTsn777bXP5N7X15esr1+/Pll///33a972pSzPcf6fSrpzguf/093bs38Vgw+gtVQMv7vvl3SyCb0AaKJ6zvl7zez3ZrbFzK7KrSMATVFr+H8kabGkdkklSRvLLWhmPWY2aGblf8wNQNPVFH53P+7u5919VNKPJS1LLNvv7h3u3lFrkwDyV1P4zWzuuIddkt7Jpx0AzXJZpQXMbLukWyV9ycyGJH1f0q1m1i7JJR2V9N0G9gigAfg+P+oya9asZP3uu+8uW6v0WwFm6eHqffv2JeudnZ3J+lTF9/kBJBF+ICjCDwRF+IGgCD8QFOEHgmKoD4X57LPPkvXLLktfhjIyMpKs33HHHWVrr7zySnLdSxlDfQCSCD8QFOEHgiL8QFCEHwiK8ANBEX4gqIrf50dsN9xwQ7J+//33J+s33nhj2VqlcfxKDh06lKzv37+/rtef6tjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQjPNPcUuWLEnWe3t7k/V77703WZ8zZ86ke6rW+fPnk/VSqZSsj46O5tnOlMOeHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCqjjOb2bzJW2TNEfSqKR+d/+hmbVJ2iFpoaSjkh5w9w8b12pclcbSu7u7y9YqjeMvXLiwlpZyMTg4mKyvX78+Wd+1a1ee7YRTzZ5/RNK/uftXJX1d0hozu07So5JecvdrJL2UPQZwiagYfncvufuB7P5pSYclzZO0UtLWbLGtku5pVJMA8jepc34zWyjpa5IGJM1295I09gdC0tV5Nwegcaq+tt/MvijpOUnfc/dTZlVNByYz65HUU1t7ABqlqj2/mX1BY8H/mbs/nz193MzmZvW5kk5MtK6797t7h7t35NEwgHxUDL+N7eJ/Iumwu28aV9olaVV2f5Wknfm3B6BRKk7RbWbLJf1G0tsaG+qTpHUaO+//paQFkv4s6VvufrLCa4Wconv27NnJ+nXXXZesP/3008n6tddeO+me8jIwMJCsP/nkk2VrO3em9xd8Jbc21U7RXfGc391/K6nci90+maYAtA6u8AOCIvxAUIQfCIrwA0ERfiAowg8ExU93V6mtra1sra+vL7lue3t7sr5o0aKaesrDa6+9lqxv3LgxWd+zZ0+y/sknn0y6JzQHe34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOP9NN92UrK9duzZZX7ZsWdnavHnzauopLx9//HHZ2ubNm5PrPvHEE8n62bNna+oJrY89PxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EFWacv6urq656PQ4dOpSs7969O1kfGRlJ1lPfuR8eHk6ui7jY8wNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUObu6QXM5kvaJmmOpFFJ/e7+QzN7TNJqSX/NFl3n7r+q8FrpjQGom7tbNctVE/65kua6+wEzmynpDUn3SHpA0hl3f6rapgg/0HjVhr/iFX7uXpJUyu6fNrPDkor96RoAdZvUOb+ZLZT0NUkD2VO9ZvZ7M9tiZleVWafHzAbNbLCuTgHkquJh/98WNPuipFclrXf3581stqQPJLmkH2js1OChCq/BYT/QYLmd80uSmX1B0m5Je9x90wT1hZJ2u/vSCq9D+IEGqzb8FQ/7zcwk/UTS4fHBzz4IvKBL0juTbRJAcar5tH+5pN9IeltjQ32StE5St6R2jR32H5X03ezDwdRrsecHGizXw/68EH6g8XI77AcwNRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCavYU3R9I+r9xj7+UPdeKWrW3Vu1Lorda5dnbP1a7YFO/z/+5jZsNuntHYQ0ktGpvrdqXRG+1Kqo3DvuBoAg/EFTR4e8vePsprdpbq/Yl0VutCumt0HN+AMUpes8PoCCFhN/M7jSzI2b2rpk9WkQP5ZjZUTN728wOFj3FWDYN2gkze2fcc21m9msz+1N2O+E0aQX19piZvZ+9dwfN7F8L6m2+mb1sZofN7A9m9kj2fKHvXaKvQt63ph/2m9k0SX+U1ClpSNLrkrrd/VBTGynDzI5K6nD3wseEzexfJJ2RtO3CbEhm9h+STrr7huwP51Xu/u8t0ttjmuTMzQ3qrdzM0t9Rge9dnjNe56GIPf8ySe+6+3vufk7SLyStLKCPlufu+yWdvOjplZK2Zve3auw/T9OV6a0luHvJ3Q9k909LujCzdKHvXaKvQhQR/nmS/jLu8ZBaa8pvl7TXzN4ws56im5nA7AszI2W3Vxfcz8UqztzcTBfNLN0y710tM17nrYjwTzSbSCsNOXzD3f9Z0l2S1mSHt6jOjyQt1tg0biVJG4tsJptZ+jlJ33P3U0X2Mt4EfRXyvhUR/iFJ88c9/rKkYwX0MSF3P5bdnpD0gsZOU1rJ8QuTpGa3Jwru52/c/bi7n3f3UUk/VoHvXTaz9HOSfubuz2dPF/7eTdRXUe9bEeF/XdI1ZvYVM5su6duSdhXQx+eY2YzsgxiZ2QxJ31TrzT68S9Kq7P4qSTsL7OXvtMrMzeVmllbB712rzXhdyEU+2VDGf0maJmmLu69vehMTMLNFGtvbS2PfePx5kb2Z2XZJt2rsW1/HJX1f0n9L+qWkBZL+LOlb7t70D97K9HarJjlzc4N6Kzez9IAKfO/ynPE6l364wg+IiSv8gKAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8E9f/Ex0YKZYOZcwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Initial python model\n",
    "- weights receives random values 784 in and 10 out\n",
    "- bias initialized with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.randn(784,10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias=torch.zeros(10);bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication pseudocode\n",
    "- function of matrix multiplication\n",
    "- review of matrix multiplication from matrixmultiplication.xyz\n",
    "    - A few loops going on: three\n",
    "- def matmul\n",
    "- ar and ac receive shape of matrix a\n",
    "- br and bc receives shape of matrix be\n",
    "-  assert the shapes of ac and br are the same\n",
    "- c receives zeros with shape ar and br\n",
    "- for i in range ar\n",
    "    - for j in range\n",
    "        - for k in range(ac):\n",
    "            - c(i,j)...\n",
    "\n",
    "- m1 receives x_validation\n",
    "- m2 receives weights\n",
    "- time the usage of matrix multiplication\n",
    "    - result 800ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac):\n",
    "                c[i,j]+=a[i,k]*b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1=x_valid[:5]\n",
    "m2=weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape, m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 978 ms, sys: 5.3 ms, total: 983 ms\n",
      "Wall time: 991 ms\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **the multiplication is quite slow. Let's try to speed it up**\n",
    "    - Every layer would take about 10 hours\n",
    "    - That's why we don't write things on pure python\n",
    "    - Let's try to speed this up\n",
    "    - Let's pass the backend to pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise operations\n",
    "- a receives a tensor\n",
    "- b receives another nesor\n",
    "- sum both tensors\n",
    "- a less tham b conveted to a float and get their mean\n",
    "- m receives a tensor matrix\n",
    "- **calculate frobenius norm**\n",
    "- trying to translate equations into code\n",
    "- sum is two for loops, one in i and other in j\n",
    "- square of the sum of all the terms\n",
    "- Howard dont write latex :)\n",
    "    - He copy and paste from google wikipedia\n",
    "- m times m sum and sware root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  5., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=tensor([10., 5, -4])\n",
    "b=tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 13.,  3.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a<b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=tensor([[1.,2,3],[4,5,6],[7,8,9]]);m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frobenius norm:\n",
    "$$||A||_F = (\\sum_{i,j=1}^{n}|a_{i,j}|^2)^{1/2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The previous equation is replicated with this code\n",
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elementwise matmul\n",
    "- replace third loop with frobenius norm\n",
    "- c = a_i + b_j . sum\n",
    "- time is 700 faster\n",
    "- backend in C\n",
    "- let's check if it is right\n",
    "- define function near(a,b) using torch. allclose()\n",
    "- test_near receives test(near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            c[i,j]=(a[i,:]*b[:,j]).sum() # Using Frobenius norm\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.61 ms ± 176 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'611.04 times faster'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{941/1.54:.2f} times faster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b):\n",
    "    return torch.allclose(a,b,rtol=1e-3,atol=1e-5)\n",
    "\n",
    "def test_near(a,b):\n",
    "    test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's get rid of one more loop\n",
    "\n",
    "#### Broadcasting\n",
    "- run at cuda\n",
    "- remove loops\n",
    "- describes how arrays with differents shapes are treated during arithmetic operations\n",
    "- first used in numpy\n",
    "- is like a new programming language\n",
    "- a > 0 comparing tensor with value, it works because of 0 is being broadcast to have same dimension as a\n",
    "- a+1 also broadcast 1 to the tensor a\n",
    "- 2*m broadcasts 2 to tm\n",
    "\n",
    "- **broadcast with a scalar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  5., -4.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a>0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we able to do a>0? 0 is bein broadcast to have the same dimensions as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.,  6., -3.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.],\n",
       "        [14., 16., 18.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting a vector to a matrix\n",
    "- c receives a tensor\n",
    "- m and c have different shapes (3x3) and (3x1)\n",
    "- array is broadcasted to\n",
    "- theres no loop but it looks like as there was a loop\n",
    "- c.expand_as(m)\n",
    "- version of c as a broadcast tensor rank 2 instead of array\n",
    "- c speed with no looop\n",
    "- t.storashe show sthat thers onl 3 values bein stored\n",
    "- b.stride()\n",
    "- tensor behave like higher rank things\n",
    "\n",
    "what if we want to take a column instead fo a row?\n",
    "- c.unsqueeze(0j=) is a shape one comma 3\n",
    "- c.unsqueeze 1 is a shape three coma one\n",
    "- this is interesting because\n",
    "- c none columns is is same shape 1 and c : none is same of squeeze 1\n",
    "- c[:, None].expand as m broadcast as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]);c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c+m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really copy the rows, but it looks as if we did. In fcat, the rows are given a stride of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = c.expand_as(m);t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Review of Rank (personal notes):** The rank of a matrix A is the dimension of the vector space generated by its columns. Corresponde to the maximal number of linearly independent columns of A. For example:_\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/1bf2b250d0de299673e8a5538de6e7a9eeb74e42\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -4.005ex; width:15.601ex; height:9.176ex;\" alt=\"{\\displaystyle {\\begin{bmatrix}1&amp;0&amp;1\\\\-2&amp;-3&amp;1\\\\3&amp;3&amp;0\\end{bmatrix}}}\">\n",
    "\n",
    "_has rank 2: the first two columns are linearly independent, so the rank is at least 2, but since the third is a linear combination of the first two (the second subtracted from the first (the second subtracted from the first), the three columns are linearly dependent so the rank must be less than 3._\n",
    "\n",
    "_The matrix_\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/fa97694618119aeec3bc66382bc7219d052beaff\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -2.505ex; width:25.09ex; height:6.176ex;\" alt=\"A=\\begin{bmatrix}1&amp;1&amp;0&amp;2\\\\-1&amp;-1&amp;0&amp;-2\\end{bmatrix}\">\n",
    "\n",
    "_has rank 1: there are nonzero columns, so the rank is positive, but any pair of colums is linearly dependent. Also $A^T$ has always the same rank_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10., 20., 30.]), tensor([[10., 20., 30.]]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, c.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c.unsqueeze(0).shape, c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instead of using unqueeze, we can use None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10., 20., 30.]), tensor([[10., 20., 30.]]), tensor([[10.],\n",
       "         [20.],\n",
       "         [30.]]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, c[None, :], c[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c[None, :].shape, c[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:, None, None, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].shape, c[...,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[...,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [24., 25., 26.],\n",
       "        [37., 38., 39.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m+c[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting in Excel\n",
    "- semicol and none is column and note afer is row\n",
    "\n",
    "### Eliminating loops with broadcasting\n",
    "- The entire row of c[i] (which is c i : (you can eliminate the semicolomns)\n",
    "- ci receives row i of a. unsqueeze (-1) which is the last dimension\n",
    "- you can also write a, i None instad of -1\n",
    "- rank 2 tensor and b is also a rank 2 tensor. unsqueeze to broadcast into b and then sum them over the rows (dim 0)\n",
    "- **Homework:** Why this works??\n",
    "\n",
    "\n",
    "- 3200 faster now with broadcasting\n",
    "- getting rid of looops also reduces errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "    #    for j in range(bc):\n",
    "    #        c[i,j]=(a[i,:]*b[:,j]).sum()\n",
    "        c[i,:] = (a[i].unsqueeze(-1)*b).sum(dim=0)\n",
    "        #c[i]=(a[i,None]*b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 µs ± 129 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1,m2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5.95 faster than previous'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{1630/274:.2f} faster than previous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Homework \n",
    "- [x] **HOMEWORK:** Convince yourself on why `c[i,:] = (a[i].unsqueeze(-1)*b).sum(dim=0)` works\n",
    "\n",
    "##### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 1.],\n",
      "        [0., 1., 0.],\n",
      "        [2., 3., 4.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5.],\n",
       "        [6., 7.],\n",
       "        [1., 8.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking two matrices from matrixmultplication.xyz\n",
    "a = tensor([[1.,2,1],[0,1,0],[2,3,4]]);print(a)\n",
    "b = tensor([[2.,5],[6,7],[1,8]]);b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's demonstrate manually the matmul function\n",
    "ar,ac=a.shape #nrows * ncols\n",
    "br,bc=b.shape\n",
    "c=torch.zeros(ar,bc)\n",
    "list(range(ar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 2)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ar, ac, br, bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first manually iterate\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 1.])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets debug (a[i].unsqueeze(-1)*b).sum(dim=0)\n",
    "a[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [1.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[i].unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 5.],\n",
       "        [6., 7.],\n",
       "        [1., 8.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  5.],\n",
       "        [12., 14.],\n",
       "        [ 1.,  8.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[i].unsqueeze(-1)*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(42.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15., 27.])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7., 26.,  9.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[i].unsqueeze(-1)*b).sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6., 7.])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add one more iteration\n",
    "i=1\n",
    "(a[i].unsqueeze(-1)*b).sum(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[15., 27.],\n",
       "        [ 6.,  7.],\n",
       "        [26., 63.]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected answer\n",
    "matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting rules\n",
    "- c[None, :] is row based\n",
    "- shape 1 by 3\n",
    "- eleentwise multiplication\n",
    "- c times c[:, none] value by value matrix\n",
    "- broadcast into squared\n",
    "- they dont have to be in the same rank\n",
    "- you can normalize by channel with no limnes of code\n",
    "- **Class Break**\n",
    "  - Goal make code faster\n",
    "  - how to do our own stuff\n",
    "  - how to write codes fast\n",
    "  - broadcast trick is one of the best for making loops fater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30])\n",
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 200., 300.],\n",
       "        [200., 400., 600.],\n",
       "        [300., 600., 900.]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]*c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 0]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None]>c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When operating on two arrays/tensors, Numpy/PyTroch compares their shapes element-wise. It satarts with the trailing dimensions, and works its way foward. Two dimensions are compatible when\n",
    "- They are equal, or\n",
    "- One of them is 1, in whic case that dimension is broadcasted to make it the same size\n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a $256*256*3$ array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein summation\n",
    "- Popularized by einsteing for higher rank matrix\n",
    "- Compact representation for combining products and sums in a general way\n",
    "- if pytorch didnt have batchwise multiplication, noe new index oadded would transform it\n",
    "- c i j + a i k times b , j\n",
    "- a i k k j -> i j\n",
    "    - using index inside string for notation and matrix\n",
    "- def matmul(a,b) return torch.einsum('ik,kj->ij', a, b)\n",
    "- now it is 16 times faster using einstein sum\n",
    "- tragedy that it exists\n",
    "- a programming language using string\n",
    "- amazing but so few things it does\n",
    "- I want to generalize to a language\n",
    "- hope is that swift give ability to write stuffs that really fast\n",
    "- swift is even faster than einsum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "def matmul(a,b):\n",
    "    ar,ac=a.shape #nrows * ncols\n",
    "    br,bc=b.shape\n",
    "    assert ac==br\n",
    "    c=torch.zeros(ar,bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac):\n",
    "                c[i,j]+=a[i,k]*b[k,j] # <-- Get this portion\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# c[i,j]+=a[i,k]*b[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "# [i,j]+=[i,k]*[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4\n",
    "# [i,k]*[k,j]->[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5\n",
    "# ik,kj->ij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    return torch.einsum('ik,kj->ij', a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 33.90 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "277 µs ± 555 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.09 faster than previous'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{274/67:.2f} faster than previous'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14776.12 faster than first attempt'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'{990e3/67:.2f} faster than first attempt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch operator\n",
    "- use pytorchs function or operator directly for matrix multiplication\n",
    "- 50 thousand faster\n",
    "- m1.matmul\n",
    "- divide into batches, written into assemb, blal, library of linear algebra, for example cuBlAS\n",
    "- awfaw, bc program is limited to a subset of thinks that BLAS can write read\n",
    "- limited to python methods\n",
    "- people working on this on swift\n",
    "- facebook research and tensor compresions\n",
    "- in python we are restricted to m1.matmul\n",
    "- pure ehanced way with einsum is 10 thousand slower\n",
    "- need of libraries\n",
    "- t2 = m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 21.79 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "26.9 µs ± 49.2 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.74 faster than previous\n",
      "58235.29 faster than first attempt\n"
     ]
    }
   ],
   "source": [
    "print(f'{67/17.9:.2f} faster than previous')\n",
    "print(f'{990e3/17:.2f} faster than first attempt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2=m1@m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using as default for matrix multiplication\n",
    "\n",
    "## [1:23:00](https://youtu.be/4u8FxNEDUeg?t=5002) Notebook 02 Fully Connected Layers (file [02_fully_connected.ipynb](https://github.com/fastai/fastai_docs/blob/master/dev_course/dl2/02_fully_connected.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The foward and backward passes\n",
    "- x train, y train, x y get data\n",
    "- get standard deviation\n",
    "- normalize using standard deviation\n",
    "- note use training, not validation mean for normalizing validation set\n",
    "- afer doing that mean is close to zero and std close to 1\n",
    "- test function if it is really normalized\n",
    "- n,m get xtrain shape\n",
    "- c output size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m__pycache__\u001b[m\u001b[m/ nb_00.py     nb_01.py     nb_02.py\r\n"
     ]
    }
   ],
   "source": [
    "ls exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted lesson-8-jupyter.ipynb to nb_lesson-8-jupyter.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv exp/nb_lesson-8-jupyter.py exp/nb_01.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_01 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_data():\n",
    "    path = datasets.download_data(MNIST_URL, ext='.gz')\n",
    "    with gzip.open(path, 'rb') as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "    return map(tensor, (x_train, y_train, x_valid, y_valid))\n",
    "\n",
    "def normalize(x,m,s):\n",
    "    return (x-m)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_valid, y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1304), tensor(0.3073))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std=x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = normalize(x_train, train_mean, train_std)\n",
    "#NB: Use training mean, not validation mean for val set\n",
    "# -Because the two datasets would be in different scales\n",
    "x_valid = normalize(x_valid, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0001), tensor(1.))"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean, train_std = x_train.mean(), x_train.std()\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def test_near_zero(a, tol=1e-3):\n",
    "    assert a.abs()<tol, f'Near zero:{a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(x_train.mean())\n",
    "test_near_zero(1-x_train.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, tensor(10))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "n,m,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Foundations version\n",
    "### Basic architecture\n",
    "\n",
    "- Model has one hidden layer\n",
    "- Foundations version\n",
    "- basic architecture\n",
    "- number of hidden layers  nhis 50\n",
    "- two layers is two wegiths and biases matrices\n",
    "- w1 is random values divided by sqare root of m\n",
    "- b are zeros\n",
    "- w2 is random values (nh,1) divided by math sqarue of nh\n",
    "- t is linear of three vectors\n",
    "- divide by sqare root m then tensor has lower values\n",
    "- simplified kaiming initialization, wrote a paper about it\n",
    "- test mean and standard of weight 1\n",
    "- thing that really matters when training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num hidden\n",
    "nh=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified kaiming init / he init\n",
    "w1 = torch.randn(m,nh)/math.sqrt(m) #m is 28*28, input size\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)/math.sqrt(nh)\n",
    "b2 = torch.zeros(1) # To simplify we'll have one output for MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 1])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near_zero(w1.mean())\n",
    "test_near_zero(w1.std()-1/math.sqrt(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0057), tensor(0.9924))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be near 1 and 1\n",
    "x_valid.mean(), x_valid.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin(x, w, b):\n",
    "    return x@w+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = lin(x_valid, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0282), tensor(1.0168))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#... so should this, because we used kaimin init, which is designed to do this\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the previous initialization, the linear initialization also propagates a mean near zero and a std near one\n",
    "\n",
    "\n",
    "- **[1] Fixup initialization:** https://arxiv.org/abs/1901.09321\n",
    "    - paper with 10000 layers just with careful initialization\n",
    "- how initialization is made really matters\n",
    "- spend a lot of time on this in depth\n",
    "- first layer is defined by relu\n",
    "- relu is grag data and clamp min to z (replace negative to zero)\n",
    "- try to find the function internal on pytorch\n",
    "\n",
    "- unfortunatelly does not have mean zero and std of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return x.clamp_min(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.3855), tensor(0.5797))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Unforunatelly doest not have zero mean and std of 1\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From pytorch docs, `a: the negative slope of the rectifier used after this layer (0 for ReLU by default)`\n",
    "\n",
    "$$std = \\sqrt{2/{(1+a^2)*\\text{fan_in}}}$$\n",
    "\n",
    "\n",
    "- demonstration\n",
    "    - distribution of data\n",
    "    - then took evertyhing smaller and took out\n",
    "    - obviously mean and std are gong to differ\n",
    "![Screen Shot 2019-03-19 at 11 29 08](https://user-images.githubusercontent.com/5733246/54631965-46545000-4a3a-11e9-82bc-c27e7c59dff8.png)\n",
    "\n",
    "\n",
    "\n",
    "- **[2] Surpassing human level performance on imagenet classification**: https://arxiv.org/abs/1502.01852\n",
    "    - > one of the most extraordinary papers in the last few years\n",
    "    - full of great ideas\n",
    "    - From resnet winners\n",
    "    - read papers from competition winners if a great idea\n",
    "    - where competition ideas has 20 good ideas\n",
    "    - kine initialization\n",
    "    - Section 2.2 initialization of filter weights for rectifiers\n",
    "    - are easier to train cbut a bat initializatiom still hamper the learning of a non linear system\n",
    "    - initializet with random gaussian distributions\n",
    "    - glorot and benchi proposded a new initialization\n",
    "        - Does not account for relu\n",
    "    \n",
    "- **[3] (glorot) Understanding the difficulty of training deep feedforward neural networks**: http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf\n",
    "    - Very readable and practical\n",
    "    - well be reimplementing stuffs from the paper\n",
    "    - Final result solution is simple\n",
    "    - **One suggestion is another approach called normalized initialization**\n",
    "        - Based on the square root\n",
    "\n",
    "- [2](https://arxiv.org/abs/1502.01852) pointed out that the initializatoin does not account for relu\n",
    "    - super simple solution is to replace the one in the top to a two in the top of the initializaton\n",
    "    - $$std = sqrt(2/((1+a^2) * fan_in))$$\n",
    "    - closer to std 1 and mean zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaiming init/he init for relu\n",
    "w1 = torch.randn(m,nh)*math.sqrt(2/m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0005), tensor(0.0503))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5397), tensor(0.8270))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = relu(lin(x_valid, w1, b1))\n",
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much closer to our goal (although not perfect)\n",
    "\n",
    "- **[ ]!!HOMEWORK: Read 2.2 of [2](https://arxiv.org/abs/1502.01852)**\n",
    "\n",
    "#### Foward propagation layer\n",
    "\n",
    "take it throuh step by step.\n",
    "6 paragraphs to read\n",
    "!! read section foward\n",
    "> \"this leads to a zero-mean gaussian distribution whose standar deviation\"\n",
    "\n",
    "- something new and obvious is to replace relu to x.clamp_min(0)-0.5 which will return to the correct mean\n",
    "\n",
    "he had to add a mode callsed fan out\n",
    "- fan ipreserves the magnitudes in the output pass\n",
    "    - Dividing by the fifrst or second\n",
    "- we need it because the weights shape is 784 by 50 while a linear torch is 50 by 784\n",
    "- look into source code to undertand using double question mark\n",
    "- it calls F.linear (F.nn.functional)\n",
    "- letds look\n",
    "- a linear layer with their transposed\n",
    "- thats why we gave the oposite when compared to torch code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = torch.zeros(m,nh)\n",
    "init.kaiming_normal_(w1, mode='fan_out') #kinda have to give the opposite information because in pytorch it was transposed\n",
    "t = relu(lin(x_valid, w1, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init.kaiming_normal_??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0002), tensor(0.0506))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.mean(), w1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6297), tensor(0.8830))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.mean(), t.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784, 50])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 784])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Linear(m,nh).weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wat if..??\n",
    "def relu(x):\n",
    "    return x.clamp_min(0)-0.5\n",
    "# Might return to the expected mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- what about conv layers??\n",
    "    - check documentation\n",
    "    - mostly documentation\n",
    "    - mostly code is under $_ConvND$_\n",
    "    - at the very bottong theres the file conv\n",
    "    - it has a special multiplier math.sqrt(5)\n",
    "        - seem to work pretty badly\n",
    "        - always a good idea to add comment\n",
    "- feeling that this is not great\n",
    "- we desined our own activation function\n",
    "    - of relu minus 0.5\n",
    "- using it the mean is almost zero and variance is almost one\n",
    "- make sense why this makes better results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.0028), tensor(0.7605))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.randn(m,nh)*math.sqrt(2./m)\n",
    "t1 = relu(lin(x_valid, w1, b1))\n",
    "t1.mean(), t1.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    l1 = lin(xb, w1, b1) # one linear layer\n",
    "    l2 = relu(l1) # relu\n",
    "    l3 = lin(l2, w2, b2) # other linear layer\n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.1 ms ± 896 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=model(x_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function: MSE\n",
    "- simplify things using mean square error\n",
    "- expect a single vector\n",
    "- use squeze to get rid in output.squeeze()\n",
    "- very common broke code because squeeze into a scaler\n",
    "better to put dimension in squeeze (-1) for example\n",
    "y train, y validation get floats\n",
    "\n",
    "get the mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x_valid).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need squeeze() to get rid of that trailing (,1) in order to use mse. (of course, mse is not suitable for multiclassification, well use better loss function soon. We'll use mse for now to keep things simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(output, targ):\n",
    "    return (output.squeeze(-1)-targ).pow(2).mean() #better to say which dimmension to squeeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4207)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test\n",
    "model(x_valid).squeeze().pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_valid = y_train.float(), y_valid.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 1])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.6899)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1:48:00](https://youtu.be/4u8FxNEDUeg?t=6484) \n",
    "\n",
    "### Gradients and backward pass\n",
    "- paper the matrix calculus you need for deep learning html by jeremy howard and terence parr: https://explained.ai/matrix-calculus/index.html\n",
    "\n",
    "- > all you need to know is the chain rule\n",
    "\n",
    "- start with an input, then a linear layer then a relu then second linear layer, then mse then y pred\n",
    "\n",
    "- other way is\n",
    "- y_pred = mse(lin2(relu(lin1(x))),y)\n",
    "![Screen Shot 2019-03-23 at 18.12.47.png](https://udacity-reviews-uploads.s3.us-west-2.amazonaws.com/_attachments/38140/1553390082/Screen_Shot_2019-03-23_at_18.12.47.png)\n",
    "\n",
    "![Screen Shot 2019-03-23 at 18.13.47.png](https://udacity-reviews-uploads.s3.us-west-2.amazonaws.com/_attachments/38140/1553390083/Screen_Shot_2019-03-23_at_18.13.47.png)\n",
    "\n",
    "- we want the gradient of the ouput y with the respect of the input x\n",
    "- y equals to f(u)\n",
    "- u equals to f(x)\n",
    "- derivatie dy/dx is dy/dy times du/dx\n",
    "- thats all you need to know\n",
    "- usually it is not treated as division, but you actually you can\n",
    "- dividing small change in y by small change in x\n",
    "- start with mean squared error\n",
    "    - gradient of the loss with respect to outputprevious layer\n",
    "    - it is two times error\n",
    "    \n",
    "- def mse_grad(input, target)\n",
    "- the input of mse is the output of previous layer\n",
    "- def gradient of relu\n",
    "- either zero or 1 which is inp > 0 dot float times out.g\n",
    "\n",
    "- linear gradient defined\n",
    "- def foward and backward\n",
    "- in backward pass\n",
    "- mse_grad\n",
    "- lin_grad\n",
    "- relu_grad\n",
    "- value inp.g is updated in each function\n",
    "- loss is the mse we never use it\n",
    "- the loss never appears in the gradients\n",
    "- so w1.g w2.g ans so on contain the gradients\n",
    "- let's clone weights and biases and test them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_grad(inp, targ):\n",
    "    # grad of loss with respect to output\n",
    "    inp.g = 2. * (inp.squeeze() - targ).unsqueeze(-1) / inp.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_grad(inp, out):\n",
    "    # Grad of Relu with respect to input activation\n",
    "    inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lin_grad(inp, out, w, b):\n",
    "    # grad of matmul with respect to input\n",
    "    inp.g = out.g @ w.t()\n",
    "    w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)\n",
    "    b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foward_and_backward(inp, targ):\n",
    "    # foward pass:\n",
    "    l1 = inp@w1+b1\n",
    "    l2 = relu(l1)\n",
    "    out = l2@w2+b2\n",
    "    # we don't need the loss in backward\n",
    "    loss = mse(out,targ)\n",
    "    \n",
    "    #backward pass\n",
    "    mse_grad(out,targ)\n",
    "    lin_grad(l2, out, w2, b2)\n",
    "    relu_grad(l1, l2)\n",
    "    lin_grad(inp, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = x_train\n",
    "targ = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = inp @ w1 + b1\n",
    "l2 = relu(l1)\n",
    "out = l2 @ w2 + b2\n",
    "# we don't actually need the loss in backward!\n",
    "loss = mse(out, targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_grad(out,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_grad(l2, out, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "out=l1\n",
    "w=w1\n",
    "b=b1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad of matmul with respect to input\n",
    "inp.g = out.g @ w.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#w.g = (inp.unsqueeze(-1) * out.g.unsqueeze(1)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]],\n",
       "\n",
       "        [[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]],\n",
       "\n",
       "        [[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]],\n",
       "\n",
       "        [[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]],\n",
       "\n",
       "        [[-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         ...,\n",
       "         [-0.4244],\n",
       "         [-0.4244],\n",
       "         [-0.4244]]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2450e-06, -9.5150e-06,  2.3526e-05,  ..., -1.0233e-05,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[ 0.0000e+00,  0.0000e+00, -1.7675e-06,  ...,  0.0000e+00,\n",
       "          -1.3278e-06, -0.0000e+00]],\n",
       "\n",
       "        [[-1.0193e-06, -0.0000e+00,  0.0000e+00,  ..., -8.3778e-06,\n",
       "           0.0000e+00,  1.4117e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -1.7985e-05,\n",
       "           0.0000e+00,  3.0304e-05]],\n",
       "\n",
       "        [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00]],\n",
       "\n",
       "        [[-2.3229e-06, -0.0000e+00,  0.0000e+00,  ..., -1.9093e-05,\n",
       "           0.0000e+00,  0.0000e+00]]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.g.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = (inp.unsqueeze(-1) @ out.g.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-751179d636bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlin_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-177-6e91c3dbe30c>\u001b[0m in \u001b[0;36mlin_grad\u001b[0;34m(inp, out, w, b)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlin_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# grad of matmul with respect to input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": [
    "lin_grad(x_train, l1, w1, b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-25f444cf28fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfoward_and_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-8215a0ac4f08>\u001b[0m in \u001b[0;36mfoward_and_backward\u001b[0;34m(inp, targ)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlin_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrelu_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mlin_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-177-6e91c3dbe30c>\u001b[0m in \u001b[0;36mlin_grad\u001b[0;34m(inp, out, w, b)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# grad of matmul with respect to input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "foward_and_backward(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_grad(out,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-221-69c41ba39853>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb1g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mb2g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": [
    "# Save for testing against later\n",
    "w1g = w1.g.clone()\n",
    "w2g = w2.g.clone()\n",
    "b1g = b1.g.clone()\n",
    "b2g = b2.g.clone()\n",
    "ig = x_train.g.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we cheat a little bit and use pytorch autograd required grad to check our results\n",
    "- using test near to check if results are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt2 = x_train.clone().requires_grad_(True)\n",
    "w12 = w1.clone().requires_grad_(True)\n",
    "w22 = w2.clone().requires_grad_(True)\n",
    "b12 = b1.clone().requires_grad_(True)\n",
    "b22 = b2.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Layers as classes\n",
    "Refactory\n",
    "- recreating pytorch api\n",
    "\n",
    "class Relu()\n",
    "    def __call__ # treat relu as a function and call whats inside\n",
    "    safe input and outpu\n",
    "    def backpro self.inp.g = self.float.self.out\n",
    "\n",
    "\n",
    "for linear compute self.w.g in backward\n",
    "\n",
    "** backward always compute .g**\n",
    "\n",
    "Class model\n",
    "\n",
    "\n",
    "init has w1, b1, w2, b2\n",
    "\n",
    "def call with x and target\n",
    "\n",
    "def backwar with self.loss.backward() to save loss.g\n",
    "\n",
    "w1.g, b1.g w2.g\n",
    "model =\n",
    "\n",
    "However, that was slow!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu():\n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp.clamp_min(0)-0.5\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = (self.inp>0).float() * self.out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin():\n",
    "    def __init__(self, w, b):\n",
    "        self.w, self.b = w,b\n",
    "        \n",
    "    def __call__(self, inp):\n",
    "        self.inp = inp\n",
    "        self.out = inp@self.w + self.b\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = self.out.g @ self.w.t()\n",
    "        # Creating a giant outer product, just to sum it, is inneficiet\n",
    "        self.w.g = (self.inp.unsqueeze(-1)*self.out.g.unsqueeze(1)).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse():\n",
    "    def __call__(self, inp, targ):\n",
    "        self.inp = inp\n",
    "        self.targ = targ\n",
    "        self.out = (inp.squeeze() - targ).pow(2).mean()\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self):\n",
    "        self.inp.g = 2. * (self.inp.squeeze() - self.targ).unsqueeze(-1) / self.targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1,b1), Relu(), Lin(w2, b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x=l(x)\n",
    "            \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g, b1.g, w2.g, b2.g = [None]*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 244 ms, sys: 454 ms, total: 698 ms\n",
      "Wall time: 537 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss=model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Mse' object has no attribute 'inp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-388-92d71bb8c163>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-387-0b19eb0d5aef>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Mse' object has no attribute 'inp'"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module foward\n",
    "\n",
    "create a new def in module callde forward which initially raise not implemented\n",
    "\n",
    "class Relu(module)\n",
    "it used foward\n",
    "\n",
    "the thing to calculate the gradient with the respect to the weights, we can reexpress that with einsum\n",
    "now it is faster with einsum\n",
    "\n",
    "time it now is 143ms intesad of 3s\n",
    "\n",
    "> This is why we have to use those modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "    \n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Relu(Module):\n",
    "    def forward(self, inp): return inp.clamp_min(0.)-0.5\n",
    "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): self.w,self.b = w,b\n",
    "        \n",
    "    def forward(self, inp): return inp@self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = torch.einsum(\"bi,bj->ij\", inp, out.g)\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mse(Module):\n",
    "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
    "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self):\n",
    "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 453 ms, total: 692 ms\n",
      "Wall time: 550 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 410 ms, sys: 115 ms, total: 524 ms\n",
      "Wall time: 479 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "near:\ntensor([[  3.3106],\n        [ -1.9763],\n        [ -5.2552],\n        [ -4.6224],\n        [ -0.6235],\n        [ -1.7669],\n        [ -0.9728],\n        [ -0.2975],\n        [ -4.8763],\n        [  2.7564],\n        [  4.1308],\n        [ -8.2567],\n        [ -3.5082],\n        [  3.6036],\n        [ -2.5213],\n        [  1.5783],\n        [ -2.9128],\n        [  3.2065],\n        [  1.3771],\n        [  1.2711],\n        [ -3.4583],\n        [ -6.6105],\n        [  2.5902],\n        [  1.4582],\n        [  0.8516],\n        [  2.0295],\n        [ -0.0610],\n        [-11.9325],\n        [ -1.9607],\n        [ -0.4036],\n        [  1.2859],\n        [  3.4702],\n        [  3.3210],\n        [ -0.5364],\n        [  2.0035],\n        [-11.2006],\n        [  2.2457],\n        [ -0.1977],\n        [ -5.7233],\n        [  3.9284],\n        [  1.4838],\n        [  3.2441],\n        [  2.8886],\n        [ -2.9910],\n        [ -1.8566],\n        [ -1.8764],\n        [  4.1975],\n        [  3.3290],\n        [ -1.1284],\n        [ -1.5114]])\ntensor([[  2.1326],\n        [ -8.4081],\n        [  3.2050],\n        [ -1.0614],\n        [ -3.9283],\n        [  2.3468],\n        [ -1.9779],\n        [  3.1268],\n        [-10.3044],\n        [  0.0327],\n        [  2.4487],\n        [  3.2933],\n        [ -5.2013],\n        [  1.8300],\n        [ -5.0611],\n        [ -7.1394],\n        [  2.6343],\n        [ -0.9606],\n        [  3.2798],\n        [  3.5225],\n        [  1.9575],\n        [ -3.8827],\n        [ -7.8621],\n        [  0.1428],\n        [-11.2387],\n        [  1.1391],\n        [  1.2058],\n        [ -0.1460],\n        [-11.7274],\n        [ -0.2920],\n        [ -7.2868],\n        [  0.0262],\n        [  1.3072],\n        [ -7.8358],\n        [  2.6910],\n        [  0.5357],\n        [ -9.5467],\n        [ -2.0982],\n        [  3.3718],\n        [ -1.2137],\n        [  3.9854],\n        [ -1.3049],\n        [  2.9785],\n        [ -0.3443],\n        [  2.0311],\n        [ -2.4654],\n        [ -0.8550],\n        [ -3.0190],\n        [  0.9579],\n        [ -7.1768]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-e5c0a6f15668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb2g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai-dlpt2-notes/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fastai-dlpt2-notes/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{cname}:\\n{a}\\n{b}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[  3.3106],\n        [ -1.9763],\n        [ -5.2552],\n        [ -4.6224],\n        [ -0.6235],\n        [ -1.7669],\n        [ -0.9728],\n        [ -0.2975],\n        [ -4.8763],\n        [  2.7564],\n        [  4.1308],\n        [ -8.2567],\n        [ -3.5082],\n        [  3.6036],\n        [ -2.5213],\n        [  1.5783],\n        [ -2.9128],\n        [  3.2065],\n        [  1.3771],\n        [  1.2711],\n        [ -3.4583],\n        [ -6.6105],\n        [  2.5902],\n        [  1.4582],\n        [  0.8516],\n        [  2.0295],\n        [ -0.0610],\n        [-11.9325],\n        [ -1.9607],\n        [ -0.4036],\n        [  1.2859],\n        [  3.4702],\n        [  3.3210],\n        [ -0.5364],\n        [  2.0035],\n        [-11.2006],\n        [  2.2457],\n        [ -0.1977],\n        [ -5.7233],\n        [  3.9284],\n        [  1.4838],\n        [  3.2441],\n        [  2.8886],\n        [ -2.9910],\n        [ -1.8566],\n        [ -1.8764],\n        [  4.1975],\n        [  3.3290],\n        [ -1.1284],\n        [ -1.5114]])\ntensor([[  2.1326],\n        [ -8.4081],\n        [  3.2050],\n        [ -1.0614],\n        [ -3.9283],\n        [  2.3468],\n        [ -1.9779],\n        [  3.1268],\n        [-10.3044],\n        [  0.0327],\n        [  2.4487],\n        [  3.2933],\n        [ -5.2013],\n        [  1.8300],\n        [ -5.0611],\n        [ -7.1394],\n        [  2.6343],\n        [ -0.9606],\n        [  3.2798],\n        [  3.5225],\n        [  1.9575],\n        [ -3.8827],\n        [ -7.8621],\n        [  0.1428],\n        [-11.2387],\n        [  1.1391],\n        [  1.2058],\n        [ -0.1460],\n        [-11.7274],\n        [ -0.2920],\n        [ -7.2868],\n        [  0.0262],\n        [  1.3072],\n        [ -7.8358],\n        [  2.6910],\n        [  0.5357],\n        [ -9.5467],\n        [ -2.0982],\n        [  3.3718],\n        [ -1.2137],\n        [  3.9854],\n        [ -1.3049],\n        [  2.9785],\n        [ -0.3443],\n        [  2.0311],\n        [ -2.4654],\n        [ -0.8550],\n        [ -3.0190],\n        [  0.9579],\n        [ -7.1768]])"
     ]
    }
   ],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Without einsum\n",
    "\n",
    "repplace with matrix multiplication\n",
    "140ms\n",
    "\n",
    "implemented nn.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lin(Module):\n",
    "    def __init__(self, w, b): self.w,self.b = w,b\n",
    "        \n",
    "    def forward(self, inp): return inp@self.w + self.b\n",
    "    \n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ out.g\n",
    "        self.b.g = out.g.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1.g,b1.g,w2.g,b2.g = [None]*4\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 214 ms, sys: 407 ms, total: 620 ms\n",
      "Wall time: 444 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 504 ms, sys: 266 ms, total: 769 ms\n",
      "Wall time: 664 ms\n"
     ]
    }
   ],
   "source": [
    "%time model.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "near:\ntensor([[  3.3106],\n        [ -1.9763],\n        [ -5.2552],\n        [ -4.6224],\n        [ -0.6235],\n        [ -1.7669],\n        [ -0.9728],\n        [ -0.2975],\n        [ -4.8763],\n        [  2.7564],\n        [  4.1308],\n        [ -8.2567],\n        [ -3.5082],\n        [  3.6036],\n        [ -2.5213],\n        [  1.5783],\n        [ -2.9128],\n        [  3.2065],\n        [  1.3771],\n        [  1.2711],\n        [ -3.4583],\n        [ -6.6105],\n        [  2.5902],\n        [  1.4582],\n        [  0.8516],\n        [  2.0295],\n        [ -0.0610],\n        [-11.9325],\n        [ -1.9607],\n        [ -0.4036],\n        [  1.2859],\n        [  3.4702],\n        [  3.3210],\n        [ -0.5364],\n        [  2.0035],\n        [-11.2006],\n        [  2.2457],\n        [ -0.1977],\n        [ -5.7233],\n        [  3.9284],\n        [  1.4838],\n        [  3.2441],\n        [  2.8886],\n        [ -2.9910],\n        [ -1.8566],\n        [ -1.8764],\n        [  4.1975],\n        [  3.3290],\n        [ -1.1284],\n        [ -1.5114]])\ntensor([[  2.1326],\n        [ -8.4081],\n        [  3.2050],\n        [ -1.0614],\n        [ -3.9283],\n        [  2.3468],\n        [ -1.9779],\n        [  3.1268],\n        [-10.3044],\n        [  0.0327],\n        [  2.4487],\n        [  3.2933],\n        [ -5.2013],\n        [  1.8300],\n        [ -5.0611],\n        [ -7.1394],\n        [  2.6343],\n        [ -0.9606],\n        [  3.2798],\n        [  3.5225],\n        [  1.9575],\n        [ -3.8827],\n        [ -7.8621],\n        [  0.1428],\n        [-11.2387],\n        [  1.1391],\n        [  1.2058],\n        [ -0.1460],\n        [-11.7274],\n        [ -0.2920],\n        [ -7.2868],\n        [  0.0262],\n        [  1.3072],\n        [ -7.8358],\n        [  2.6910],\n        [  0.5357],\n        [ -9.5467],\n        [ -2.0982],\n        [  3.3718],\n        [ -1.2137],\n        [  3.9854],\n        [ -1.3049],\n        [  2.9785],\n        [ -0.3443],\n        [  2.0311],\n        [ -2.4654],\n        [ -0.8550],\n        [ -3.0190],\n        [  0.9579],\n        [ -7.1768]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-408-e5c0a6f15668>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb2g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/fastai-dlpt2-notes/exp/nb_01.py\u001b[0m in \u001b[0;36mtest_near\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_near\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/fastai-dlpt2-notes/exp/nb_01.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf'{cname}:\\n{a}\\n{b}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: near:\ntensor([[  3.3106],\n        [ -1.9763],\n        [ -5.2552],\n        [ -4.6224],\n        [ -0.6235],\n        [ -1.7669],\n        [ -0.9728],\n        [ -0.2975],\n        [ -4.8763],\n        [  2.7564],\n        [  4.1308],\n        [ -8.2567],\n        [ -3.5082],\n        [  3.6036],\n        [ -2.5213],\n        [  1.5783],\n        [ -2.9128],\n        [  3.2065],\n        [  1.3771],\n        [  1.2711],\n        [ -3.4583],\n        [ -6.6105],\n        [  2.5902],\n        [  1.4582],\n        [  0.8516],\n        [  2.0295],\n        [ -0.0610],\n        [-11.9325],\n        [ -1.9607],\n        [ -0.4036],\n        [  1.2859],\n        [  3.4702],\n        [  3.3210],\n        [ -0.5364],\n        [  2.0035],\n        [-11.2006],\n        [  2.2457],\n        [ -0.1977],\n        [ -5.7233],\n        [  3.9284],\n        [  1.4838],\n        [  3.2441],\n        [  2.8886],\n        [ -2.9910],\n        [ -1.8566],\n        [ -1.8764],\n        [  4.1975],\n        [  3.3290],\n        [ -1.1284],\n        [ -1.5114]])\ntensor([[  2.1326],\n        [ -8.4081],\n        [  3.2050],\n        [ -1.0614],\n        [ -3.9283],\n        [  2.3468],\n        [ -1.9779],\n        [  3.1268],\n        [-10.3044],\n        [  0.0327],\n        [  2.4487],\n        [  3.2933],\n        [ -5.2013],\n        [  1.8300],\n        [ -5.0611],\n        [ -7.1394],\n        [  2.6343],\n        [ -0.9606],\n        [  3.2798],\n        [  3.5225],\n        [  1.9575],\n        [ -3.8827],\n        [ -7.8621],\n        [  0.1428],\n        [-11.2387],\n        [  1.1391],\n        [  1.2058],\n        [ -0.1460],\n        [-11.7274],\n        [ -0.2920],\n        [ -7.2868],\n        [  0.0262],\n        [  1.3072],\n        [ -7.8358],\n        [  2.6910],\n        [  0.5357],\n        [ -9.5467],\n        [ -2.0982],\n        [  3.3718],\n        [ -1.2137],\n        [  3.9854],\n        [ -1.3049],\n        [  2.9785],\n        [ -0.3443],\n        [  2.0311],\n        [ -2.4654],\n        [ -0.8550],\n        [ -3.0190],\n        [  0.9579],\n        [ -7.1768]])"
     ]
    }
   ],
   "source": [
    "test_near(w2g, w2.g)\n",
    "test_near(b2g, b2.g)\n",
    "test_near(w1g, w1.g)\n",
    "test_near(b1g, b1.g)\n",
    "test_near(ig, x_train.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### nn linear and nn.module\n",
    "even faster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        self.loss = mse\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x.squeeze(), targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 232 ms, sys: 405 ms, total: 637 ms\n",
      "Wall time: 454 ms\n"
     ]
    }
   ],
   "source": [
    "%time loss = model(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 198 ms, sys: 50.2 ms, total: 248 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%time loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted lesson-8-jupyter.ipynb to nb_lesson-8-jupyter.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py lesson-8-jupyter.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv exp/nb_lesson-8-jupyter.py exp/nb_02.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
